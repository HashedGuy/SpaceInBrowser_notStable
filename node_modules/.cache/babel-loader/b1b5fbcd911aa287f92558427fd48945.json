{"ast":null,"code":"\"use strict\";\n\nvar __extends = this && this.__extends || function () {\n  var _extendStatics = function extendStatics(d, b) {\n    _extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) {\n        if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];\n      }\n    };\n\n    return _extendStatics(d, b);\n  };\n\n  return function (d, b) {\n    if (typeof b !== \"function\" && b !== null) throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n\n    _extendStatics(d, b);\n\n    function __() {\n      this.constructor = d;\n    }\n\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.charCodeToOptimizedIndex = exports.minOptimizationVal = exports.buildLineBreakIssueMessage = exports.LineTerminatorOptimizedTester = exports.isShortPattern = exports.isCustomPattern = exports.cloneEmptyGroups = exports.performWarningRuntimeChecks = exports.performRuntimeChecks = exports.addStickyFlag = exports.addStartOfInput = exports.findUnreachablePatterns = exports.findModesThatDoNotExist = exports.findInvalidGroupType = exports.findDuplicatePatterns = exports.findUnsupportedFlags = exports.findStartOfInputAnchor = exports.findEmptyMatchRegExps = exports.findEndOfInputAnchor = exports.findInvalidPatterns = exports.findMissingPatterns = exports.validatePatterns = exports.analyzeTokenTypes = exports.enableSticky = exports.disableSticky = exports.SUPPORT_STICKY = exports.MODES = exports.DEFAULT_MODE = void 0;\n\nvar regexp_to_ast_1 = require(\"regexp-to-ast\");\n\nvar lexer_public_1 = require(\"./lexer_public\");\n\nvar utils_1 = require(\"@chevrotain/utils\");\n\nvar reg_exp_1 = require(\"./reg_exp\");\n\nvar reg_exp_parser_1 = require(\"./reg_exp_parser\");\n\nvar PATTERN = \"PATTERN\";\nexports.DEFAULT_MODE = \"defaultMode\";\nexports.MODES = \"modes\";\nexports.SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\n\nfunction disableSticky() {\n  exports.SUPPORT_STICKY = false;\n}\n\nexports.disableSticky = disableSticky;\n\nfunction enableSticky() {\n  exports.SUPPORT_STICKY = true;\n}\n\nexports.enableSticky = enableSticky;\n\nfunction analyzeTokenTypes(tokenTypes, options) {\n  options = (0, utils_1.defaults)(options, {\n    useSticky: exports.SUPPORT_STICKY,\n    debug: false,\n    safeMode: false,\n    positionTracking: \"full\",\n    lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n    tracer: function tracer(msg, action) {\n      return action();\n    }\n  });\n  var tracer = options.tracer;\n  tracer(\"initCharCodeToOptimizedIndexMap\", function () {\n    initCharCodeToOptimizedIndexMap();\n  });\n  var onlyRelevantTypes;\n  tracer(\"Reject Lexer.NA\", function () {\n    onlyRelevantTypes = (0, utils_1.reject)(tokenTypes, function (currType) {\n      return currType[PATTERN] === lexer_public_1.Lexer.NA;\n    });\n  });\n  var hasCustom = false;\n  var allTransformedPatterns;\n  tracer(\"Transform Patterns\", function () {\n    hasCustom = false;\n    allTransformedPatterns = (0, utils_1.map)(onlyRelevantTypes, function (currType) {\n      var currPattern = currType[PATTERN];\n      /* istanbul ignore else */\n\n      if ((0, utils_1.isRegExp)(currPattern)) {\n        var regExpSource = currPattern.source;\n\n        if (regExpSource.length === 1 && // only these regExp meta characters which can appear in a length one regExp\n        regExpSource !== \"^\" && regExpSource !== \"$\" && regExpSource !== \".\" && !currPattern.ignoreCase) {\n          return regExpSource;\n        } else if (regExpSource.length === 2 && regExpSource[0] === \"\\\\\" && // not a meta character\n        !(0, utils_1.contains)([\"d\", \"D\", \"s\", \"S\", \"t\", \"r\", \"n\", \"t\", \"0\", \"c\", \"b\", \"B\", \"f\", \"v\", \"w\", \"W\"], regExpSource[1])) {\n          // escaped meta Characters: /\\+/ /\\[/\n          // or redundant escaping: /\\a/\n          // without the escaping \"\\\"\n          return regExpSource[1];\n        } else {\n          return options.useSticky ? addStickyFlag(currPattern) : addStartOfInput(currPattern);\n        }\n      } else if ((0, utils_1.isFunction)(currPattern)) {\n        hasCustom = true; // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n\n        return {\n          exec: currPattern\n        };\n      } else if ((0, utils_1.has)(currPattern, \"exec\")) {\n        hasCustom = true; // ICustomPattern\n\n        return currPattern;\n      } else if (typeof currPattern === \"string\") {\n        if (currPattern.length === 1) {\n          return currPattern;\n        } else {\n          var escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n          var wrappedRegExp = new RegExp(escapedRegExpString);\n          return options.useSticky ? addStickyFlag(wrappedRegExp) : addStartOfInput(wrappedRegExp);\n        }\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n  });\n  var patternIdxToType;\n  var patternIdxToGroup;\n  var patternIdxToLongerAltIdxArr;\n  var patternIdxToPushMode;\n  var patternIdxToPopMode;\n  tracer(\"misc mapping\", function () {\n    patternIdxToType = (0, utils_1.map)(onlyRelevantTypes, function (currType) {\n      return currType.tokenTypeIdx;\n    });\n    patternIdxToGroup = (0, utils_1.map)(onlyRelevantTypes, function (clazz) {\n      var groupName = clazz.GROUP;\n      /* istanbul ignore next */\n\n      if (groupName === lexer_public_1.Lexer.SKIPPED) {\n        return undefined;\n      } else if ((0, utils_1.isString)(groupName)) {\n        return groupName;\n      } else if ((0, utils_1.isUndefined)(groupName)) {\n        return false;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n    patternIdxToLongerAltIdxArr = (0, utils_1.map)(onlyRelevantTypes, function (clazz) {\n      var longerAltType = clazz.LONGER_ALT;\n\n      if (longerAltType) {\n        var longerAltIdxArr = (0, utils_1.isArray)(longerAltType) ? (0, utils_1.map)(longerAltType, function (type) {\n          return (0, utils_1.indexOf)(onlyRelevantTypes, type);\n        }) : [(0, utils_1.indexOf)(onlyRelevantTypes, longerAltType)];\n        return longerAltIdxArr;\n      }\n    });\n    patternIdxToPushMode = (0, utils_1.map)(onlyRelevantTypes, function (clazz) {\n      return clazz.PUSH_MODE;\n    });\n    patternIdxToPopMode = (0, utils_1.map)(onlyRelevantTypes, function (clazz) {\n      return (0, utils_1.has)(clazz, \"POP_MODE\");\n    });\n  });\n  var patternIdxToCanLineTerminator;\n  tracer(\"Line Terminator Handling\", function () {\n    var lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n    patternIdxToCanLineTerminator = (0, utils_1.map)(onlyRelevantTypes, function (tokType) {\n      return false;\n    });\n\n    if (options.positionTracking !== \"onlyOffset\") {\n      patternIdxToCanLineTerminator = (0, utils_1.map)(onlyRelevantTypes, function (tokType) {\n        if ((0, utils_1.has)(tokType, \"LINE_BREAKS\")) {\n          return tokType.LINE_BREAKS;\n        } else {\n          if (checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false) {\n            return (0, reg_exp_1.canMatchCharCode)(lineTerminatorCharCodes, tokType.PATTERN);\n          }\n        }\n      });\n    }\n  });\n  var patternIdxToIsCustom;\n  var patternIdxToShort;\n  var emptyGroups;\n  var patternIdxToConfig;\n  tracer(\"Misc Mapping #2\", function () {\n    patternIdxToIsCustom = (0, utils_1.map)(onlyRelevantTypes, isCustomPattern);\n    patternIdxToShort = (0, utils_1.map)(allTransformedPatterns, isShortPattern);\n    emptyGroups = (0, utils_1.reduce)(onlyRelevantTypes, function (acc, clazz) {\n      var groupName = clazz.GROUP;\n\n      if ((0, utils_1.isString)(groupName) && !(groupName === lexer_public_1.Lexer.SKIPPED)) {\n        acc[groupName] = [];\n      }\n\n      return acc;\n    }, {});\n    patternIdxToConfig = (0, utils_1.map)(allTransformedPatterns, function (x, idx) {\n      return {\n        pattern: allTransformedPatterns[idx],\n        longerAlt: patternIdxToLongerAltIdxArr[idx],\n        canLineTerminator: patternIdxToCanLineTerminator[idx],\n        isCustom: patternIdxToIsCustom[idx],\n        short: patternIdxToShort[idx],\n        group: patternIdxToGroup[idx],\n        push: patternIdxToPushMode[idx],\n        pop: patternIdxToPopMode[idx],\n        tokenTypeIdx: patternIdxToType[idx],\n        tokenType: onlyRelevantTypes[idx]\n      };\n    });\n  });\n  var canBeOptimized = true;\n  var charCodeToPatternIdxToConfig = [];\n\n  if (!options.safeMode) {\n    tracer(\"First Char Optimization\", function () {\n      charCodeToPatternIdxToConfig = (0, utils_1.reduce)(onlyRelevantTypes, function (result, currTokType, idx) {\n        if (typeof currTokType.PATTERN === \"string\") {\n          var charCode = currTokType.PATTERN.charCodeAt(0);\n          var optimizedIdx = charCodeToOptimizedIndex(charCode);\n          addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n        } else if ((0, utils_1.isArray)(currTokType.START_CHARS_HINT)) {\n          var lastOptimizedIdx_1;\n          (0, utils_1.forEach)(currTokType.START_CHARS_HINT, function (charOrInt) {\n            var charCode = typeof charOrInt === \"string\" ? charOrInt.charCodeAt(0) : charOrInt;\n            var currOptimizedIdx = charCodeToOptimizedIndex(charCode); // Avoid adding the config multiple times\n\n            /* istanbul ignore else */\n            // - Difficult to check this scenario effects as it is only a performance\n            //   optimization that does not change correctness\n\n            if (lastOptimizedIdx_1 !== currOptimizedIdx) {\n              lastOptimizedIdx_1 = currOptimizedIdx;\n              addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n            }\n          });\n        } else if ((0, utils_1.isRegExp)(currTokType.PATTERN)) {\n          if (currTokType.PATTERN.unicode) {\n            canBeOptimized = false;\n\n            if (options.ensureOptimizations) {\n              (0, utils_1.PRINT_ERROR)(\"\" + reg_exp_1.failedOptimizationPrefixMsg + (\"\\tUnable to analyze < \" + currTokType.PATTERN.toString() + \" > pattern.\\n\") + \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" + \"\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\");\n            }\n          } else {\n            var optimizedCodes = (0, reg_exp_1.getOptimizedStartCodesIndices)(currTokType.PATTERN, options.ensureOptimizations);\n            /* istanbul ignore if */\n            // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n            // the first should be a different validation and the second cannot be tested.\n\n            if ((0, utils_1.isEmpty)(optimizedCodes)) {\n              // we cannot understand what codes may start possible matches\n              // The optimization correctness requires knowing start codes for ALL patterns.\n              // Not actually sure this is an error, no debug message\n              canBeOptimized = false;\n            }\n\n            (0, utils_1.forEach)(optimizedCodes, function (code) {\n              addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n            });\n          }\n        } else {\n          if (options.ensureOptimizations) {\n            (0, utils_1.PRINT_ERROR)(\"\" + reg_exp_1.failedOptimizationPrefixMsg + (\"\\tTokenType: <\" + currTokType.name + \"> is using a custom token pattern without providing <start_chars_hint> parameter.\\n\") + \"\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\");\n          }\n\n          canBeOptimized = false;\n        }\n\n        return result;\n      }, []);\n    });\n  }\n\n  tracer(\"ArrayPacking\", function () {\n    charCodeToPatternIdxToConfig = (0, utils_1.packArray)(charCodeToPatternIdxToConfig);\n  });\n  return {\n    emptyGroups: emptyGroups,\n    patternIdxToConfig: patternIdxToConfig,\n    charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n    hasCustom: hasCustom,\n    canBeOptimized: canBeOptimized\n  };\n}\n\nexports.analyzeTokenTypes = analyzeTokenTypes;\n\nfunction validatePatterns(tokenTypes, validModesNames) {\n  var errors = [];\n  var missingResult = findMissingPatterns(tokenTypes);\n  errors = errors.concat(missingResult.errors);\n  var invalidResult = findInvalidPatterns(missingResult.valid);\n  var validTokenTypes = invalidResult.valid;\n  errors = errors.concat(invalidResult.errors);\n  errors = errors.concat(validateRegExpPattern(validTokenTypes));\n  errors = errors.concat(findInvalidGroupType(validTokenTypes));\n  errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n  errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n  return errors;\n}\n\nexports.validatePatterns = validatePatterns;\n\nfunction validateRegExpPattern(tokenTypes) {\n  var errors = [];\n  var withRegExpPatterns = (0, utils_1.filter)(tokenTypes, function (currTokType) {\n    return (0, utils_1.isRegExp)(currTokType[PATTERN]);\n  });\n  errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n  errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n  errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n  return errors;\n}\n\nfunction findMissingPatterns(tokenTypes) {\n  var tokenTypesWithMissingPattern = (0, utils_1.filter)(tokenTypes, function (currType) {\n    return !(0, utils_1.has)(currType, PATTERN);\n  });\n  var errors = (0, utils_1.map)(tokenTypesWithMissingPattern, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- missing static 'PATTERN' property\",\n      type: lexer_public_1.LexerDefinitionErrorType.MISSING_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  var valid = (0, utils_1.difference)(tokenTypes, tokenTypesWithMissingPattern);\n  return {\n    errors: errors,\n    valid: valid\n  };\n}\n\nexports.findMissingPatterns = findMissingPatterns;\n\nfunction findInvalidPatterns(tokenTypes) {\n  var tokenTypesWithInvalidPattern = (0, utils_1.filter)(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return !(0, utils_1.isRegExp)(pattern) && !(0, utils_1.isFunction)(pattern) && !(0, utils_1.has)(pattern, \"exec\") && !(0, utils_1.isString)(pattern);\n  });\n  var errors = (0, utils_1.map)(tokenTypesWithInvalidPattern, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' can only be a RegExp, a\" + \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n      type: lexer_public_1.LexerDefinitionErrorType.INVALID_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  var valid = (0, utils_1.difference)(tokenTypes, tokenTypesWithInvalidPattern);\n  return {\n    errors: errors,\n    valid: valid\n  };\n}\n\nexports.findInvalidPatterns = findInvalidPatterns;\nvar end_of_input = /[^\\\\][\\$]/;\n\nfunction findEndOfInputAnchor(tokenTypes) {\n  var EndAnchorFinder =\n  /** @class */\n  function (_super) {\n    __extends(EndAnchorFinder, _super);\n\n    function EndAnchorFinder() {\n      var _this = _super !== null && _super.apply(this, arguments) || this;\n\n      _this.found = false;\n      return _this;\n    }\n\n    EndAnchorFinder.prototype.visitEndAnchor = function (node) {\n      this.found = true;\n    };\n\n    return EndAnchorFinder;\n  }(regexp_to_ast_1.BaseRegExpVisitor);\n\n  var invalidRegex = (0, utils_1.filter)(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n\n    try {\n      var regexpAst = (0, reg_exp_parser_1.getRegExpAst)(pattern);\n      var endAnchorVisitor = new EndAnchorFinder();\n      endAnchorVisitor.visit(regexpAst);\n      return endAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return end_of_input.test(pattern.source);\n    }\n  });\n  var errors = (0, utils_1.map)(invalidRegex, function (currType) {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\" + \"\\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" + \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" + \"\\tfor details.\",\n      type: lexer_public_1.LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n\nexports.findEndOfInputAnchor = findEndOfInputAnchor;\n\nfunction findEmptyMatchRegExps(tokenTypes) {\n  var matchesEmptyString = (0, utils_1.filter)(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return pattern.test(\"\");\n  });\n  var errors = (0, utils_1.map)(matchesEmptyString, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' must not match an empty string\",\n      type: lexer_public_1.LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n\nexports.findEmptyMatchRegExps = findEmptyMatchRegExps;\nvar start_of_input = /[^\\\\[][\\^]|^\\^/;\n\nfunction findStartOfInputAnchor(tokenTypes) {\n  var StartAnchorFinder =\n  /** @class */\n  function (_super) {\n    __extends(StartAnchorFinder, _super);\n\n    function StartAnchorFinder() {\n      var _this = _super !== null && _super.apply(this, arguments) || this;\n\n      _this.found = false;\n      return _this;\n    }\n\n    StartAnchorFinder.prototype.visitStartAnchor = function (node) {\n      this.found = true;\n    };\n\n    return StartAnchorFinder;\n  }(regexp_to_ast_1.BaseRegExpVisitor);\n\n  var invalidRegex = (0, utils_1.filter)(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n\n    try {\n      var regexpAst = (0, reg_exp_parser_1.getRegExpAst)(pattern);\n      var startAnchorVisitor = new StartAnchorFinder();\n      startAnchorVisitor.visit(regexpAst);\n      return startAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return start_of_input.test(pattern.source);\n    }\n  });\n  var errors = (0, utils_1.map)(invalidRegex, function (currType) {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\" + \"\\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" + \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" + \"\\tfor details.\",\n      type: lexer_public_1.LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n\nexports.findStartOfInputAnchor = findStartOfInputAnchor;\n\nfunction findUnsupportedFlags(tokenTypes) {\n  var invalidFlags = (0, utils_1.filter)(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n  });\n  var errors = (0, utils_1.map)(invalidFlags, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n      type: lexer_public_1.LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n\nexports.findUnsupportedFlags = findUnsupportedFlags; // This can only test for identical duplicate RegExps, not semantically equivalent ones.\n\nfunction findDuplicatePatterns(tokenTypes) {\n  var found = [];\n  var identicalPatterns = (0, utils_1.map)(tokenTypes, function (outerType) {\n    return (0, utils_1.reduce)(tokenTypes, function (result, innerType) {\n      if (outerType.PATTERN.source === innerType.PATTERN.source && !(0, utils_1.contains)(found, innerType) && innerType.PATTERN !== lexer_public_1.Lexer.NA) {\n        // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n        // in essence we are creating Equivalence classes on equality relation.\n        found.push(innerType);\n        result.push(innerType);\n        return result;\n      }\n\n      return result;\n    }, []);\n  });\n  identicalPatterns = (0, utils_1.compact)(identicalPatterns);\n  var duplicatePatterns = (0, utils_1.filter)(identicalPatterns, function (currIdenticalSet) {\n    return currIdenticalSet.length > 1;\n  });\n  var errors = (0, utils_1.map)(duplicatePatterns, function (setOfIdentical) {\n    var tokenTypeNames = (0, utils_1.map)(setOfIdentical, function (currType) {\n      return currType.name;\n    });\n    var dupPatternSrc = (0, utils_1.first)(setOfIdentical).PATTERN;\n    return {\n      message: \"The same RegExp pattern ->\" + dupPatternSrc + \"<-\" + (\"has been used in all of the following Token Types: \" + tokenTypeNames.join(\", \") + \" <-\"),\n      type: lexer_public_1.LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n      tokenTypes: setOfIdentical\n    };\n  });\n  return errors;\n}\n\nexports.findDuplicatePatterns = findDuplicatePatterns;\n\nfunction findInvalidGroupType(tokenTypes) {\n  var invalidTypes = (0, utils_1.filter)(tokenTypes, function (clazz) {\n    if (!(0, utils_1.has)(clazz, \"GROUP\")) {\n      return false;\n    }\n\n    var group = clazz.GROUP;\n    return group !== lexer_public_1.Lexer.SKIPPED && group !== lexer_public_1.Lexer.NA && !(0, utils_1.isString)(group);\n  });\n  var errors = (0, utils_1.map)(invalidTypes, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n      type: lexer_public_1.LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n\nexports.findInvalidGroupType = findInvalidGroupType;\n\nfunction findModesThatDoNotExist(tokenTypes, validModes) {\n  var invalidModes = (0, utils_1.filter)(tokenTypes, function (clazz) {\n    return clazz.PUSH_MODE !== undefined && !(0, utils_1.contains)(validModes, clazz.PUSH_MODE);\n  });\n  var errors = (0, utils_1.map)(invalidModes, function (tokType) {\n    var msg = \"Token Type: ->\" + tokType.name + \"<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->\" + tokType.PUSH_MODE + \"<-\" + \"which does not exist\";\n    return {\n      message: msg,\n      type: lexer_public_1.LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n      tokenTypes: [tokType]\n    };\n  });\n  return errors;\n}\n\nexports.findModesThatDoNotExist = findModesThatDoNotExist;\n\nfunction findUnreachablePatterns(tokenTypes) {\n  var errors = [];\n  var canBeTested = (0, utils_1.reduce)(tokenTypes, function (result, tokType, idx) {\n    var pattern = tokType.PATTERN;\n\n    if (pattern === lexer_public_1.Lexer.NA) {\n      return result;\n    } // a more comprehensive validation for all forms of regExps would require\n    // deeper regExp analysis capabilities\n\n\n    if ((0, utils_1.isString)(pattern)) {\n      result.push({\n        str: pattern,\n        idx: idx,\n        tokenType: tokType\n      });\n    } else if ((0, utils_1.isRegExp)(pattern) && noMetaChar(pattern)) {\n      result.push({\n        str: pattern.source,\n        idx: idx,\n        tokenType: tokType\n      });\n    }\n\n    return result;\n  }, []);\n  (0, utils_1.forEach)(tokenTypes, function (tokType, testIdx) {\n    (0, utils_1.forEach)(canBeTested, function (_a) {\n      var str = _a.str,\n          idx = _a.idx,\n          tokenType = _a.tokenType;\n\n      if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n        var msg = \"Token: ->\" + tokenType.name + \"<- can never be matched.\\n\" + (\"Because it appears AFTER the Token Type ->\" + tokType.name + \"<-\") + \"in the lexer's definition.\\n\" + \"See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE\";\n        errors.push({\n          message: msg,\n          type: lexer_public_1.LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n          tokenTypes: [tokType, tokenType]\n        });\n      }\n    });\n  });\n  return errors;\n}\n\nexports.findUnreachablePatterns = findUnreachablePatterns;\n\nfunction testTokenType(str, pattern) {\n  /* istanbul ignore else */\n  if ((0, utils_1.isRegExp)(pattern)) {\n    var regExpArray = pattern.exec(str);\n    return regExpArray !== null && regExpArray.index === 0;\n  } else if ((0, utils_1.isFunction)(pattern)) {\n    // maintain the API of custom patterns\n    return pattern(str, 0, [], {});\n  } else if ((0, utils_1.has)(pattern, \"exec\")) {\n    // maintain the API of custom patterns\n    return pattern.exec(str, 0, [], {});\n  } else if (typeof pattern === \"string\") {\n    return pattern === str;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nfunction noMetaChar(regExp) {\n  //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n  var metaChars = [\".\", \"\\\\\", \"[\", \"]\", \"|\", \"^\", \"$\", \"(\", \")\", \"?\", \"*\", \"+\", \"{\"];\n  return (0, utils_1.find)(metaChars, function (char) {\n    return regExp.source.indexOf(char) !== -1;\n  }) === undefined;\n}\n\nfunction addStartOfInput(pattern) {\n  var flags = pattern.ignoreCase ? \"i\" : \"\"; // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n\n  return new RegExp(\"^(?:\" + pattern.source + \")\", flags);\n}\n\nexports.addStartOfInput = addStartOfInput;\n\nfunction addStickyFlag(pattern) {\n  var flags = pattern.ignoreCase ? \"iy\" : \"y\"; // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n\n  return new RegExp(\"\" + pattern.source, flags);\n}\n\nexports.addStickyFlag = addStickyFlag;\n\nfunction performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  var errors = []; // some run time checks to help the end users.\n\n  if (!(0, utils_1.has)(lexerDefinition, exports.DEFAULT_MODE)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + exports.DEFAULT_MODE + \"> property in its definition\\n\",\n      type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n    });\n  }\n\n  if (!(0, utils_1.has)(lexerDefinition, exports.MODES)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + exports.MODES + \"> property in its definition\\n\",\n      type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n    });\n  }\n\n  if ((0, utils_1.has)(lexerDefinition, exports.MODES) && (0, utils_1.has)(lexerDefinition, exports.DEFAULT_MODE) && !(0, utils_1.has)(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized with a \" + exports.DEFAULT_MODE + \": <\" + lexerDefinition.defaultMode + \">\" + \"which does not exist\\n\",\n      type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n    });\n  }\n\n  if ((0, utils_1.has)(lexerDefinition, exports.MODES)) {\n    (0, utils_1.forEach)(lexerDefinition.modes, function (currModeValue, currModeName) {\n      (0, utils_1.forEach)(currModeValue, function (currTokType, currIdx) {\n        if ((0, utils_1.isUndefined)(currTokType)) {\n          errors.push({\n            message: \"A Lexer cannot be initialized using an undefined Token Type. Mode:\" + (\"<\" + currModeName + \"> at index: <\" + currIdx + \">\\n\"),\n            type: lexer_public_1.LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n          });\n        }\n      });\n    });\n  }\n\n  return errors;\n}\n\nexports.performRuntimeChecks = performRuntimeChecks;\n\nfunction performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  var warnings = [];\n  var hasAnyLineBreak = false;\n  var allTokenTypes = (0, utils_1.compact)((0, utils_1.flatten)((0, utils_1.mapValues)(lexerDefinition.modes, function (tokTypes) {\n    return tokTypes;\n  })));\n  var concreteTokenTypes = (0, utils_1.reject)(allTokenTypes, function (currType) {\n    return currType[PATTERN] === lexer_public_1.Lexer.NA;\n  });\n  var terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n\n  if (trackLines) {\n    (0, utils_1.forEach)(concreteTokenTypes, function (tokType) {\n      var currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n\n      if (currIssue !== false) {\n        var message = buildLineBreakIssueMessage(tokType, currIssue);\n        var warningDescriptor = {\n          message: message,\n          type: currIssue.issue,\n          tokenType: tokType\n        };\n        warnings.push(warningDescriptor);\n      } else {\n        // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n        if ((0, utils_1.has)(tokType, \"LINE_BREAKS\")) {\n          if (tokType.LINE_BREAKS === true) {\n            hasAnyLineBreak = true;\n          }\n        } else {\n          if ((0, reg_exp_1.canMatchCharCode)(terminatorCharCodes, tokType.PATTERN)) {\n            hasAnyLineBreak = true;\n          }\n        }\n      }\n    });\n  }\n\n  if (trackLines && !hasAnyLineBreak) {\n    warnings.push({\n      message: \"Warning: No LINE_BREAKS Found.\\n\" + \"\\tThis Lexer has been defined to track line and column information,\\n\" + \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" + \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" + \"\\tfor details.\",\n      type: lexer_public_1.LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n    });\n  }\n\n  return warnings;\n}\n\nexports.performWarningRuntimeChecks = performWarningRuntimeChecks;\n\nfunction cloneEmptyGroups(emptyGroups) {\n  var clonedResult = {};\n  var groupKeys = (0, utils_1.keys)(emptyGroups);\n  (0, utils_1.forEach)(groupKeys, function (currKey) {\n    var currGroupValue = emptyGroups[currKey];\n    /* istanbul ignore else */\n\n    if ((0, utils_1.isArray)(currGroupValue)) {\n      clonedResult[currKey] = [];\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  });\n  return clonedResult;\n}\n\nexports.cloneEmptyGroups = cloneEmptyGroups; // TODO: refactor to avoid duplication\n\nfunction isCustomPattern(tokenType) {\n  var pattern = tokenType.PATTERN;\n  /* istanbul ignore else */\n\n  if ((0, utils_1.isRegExp)(pattern)) {\n    return false;\n  } else if ((0, utils_1.isFunction)(pattern)) {\n    // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n    return true;\n  } else if ((0, utils_1.has)(pattern, \"exec\")) {\n    // ICustomPattern\n    return true;\n  } else if ((0, utils_1.isString)(pattern)) {\n    return false;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexports.isCustomPattern = isCustomPattern;\n\nfunction isShortPattern(pattern) {\n  if ((0, utils_1.isString)(pattern) && pattern.length === 1) {\n    return pattern.charCodeAt(0);\n  } else {\n    return false;\n  }\n}\n\nexports.isShortPattern = isShortPattern;\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\n\nexports.LineTerminatorOptimizedTester = {\n  // implements /\\n|\\r\\n?/g.test\n  test: function test(text) {\n    var len = text.length;\n\n    for (var i = this.lastIndex; i < len; i++) {\n      var c = text.charCodeAt(i);\n\n      if (c === 10) {\n        this.lastIndex = i + 1;\n        return true;\n      } else if (c === 13) {\n        if (text.charCodeAt(i + 1) === 10) {\n          this.lastIndex = i + 2;\n        } else {\n          this.lastIndex = i + 1;\n        }\n\n        return true;\n      }\n    }\n\n    return false;\n  },\n  lastIndex: 0\n};\n\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n  if ((0, utils_1.has)(tokType, \"LINE_BREAKS\")) {\n    // if the user explicitly declared the line_breaks option we will respect their choice\n    // and assume it is correct.\n    return false;\n  } else {\n    /* istanbul ignore else */\n    if ((0, utils_1.isRegExp)(tokType.PATTERN)) {\n      try {\n        // TODO: why is the casting suddenly needed?\n        (0, reg_exp_1.canMatchCharCode)(lineTerminatorCharCodes, tokType.PATTERN);\n      } catch (e) {\n        /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n        return {\n          issue: lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n          errMsg: e.message\n        };\n      }\n\n      return false;\n    } else if ((0, utils_1.isString)(tokType.PATTERN)) {\n      // string literal patterns can always be analyzed to detect line terminator usage\n      return false;\n    } else if (isCustomPattern(tokType)) {\n      // custom token types\n      return {\n        issue: lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK\n      };\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n}\n\nfunction buildLineBreakIssueMessage(tokType, details) {\n  /* istanbul ignore else */\n  if (details.issue === lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n    return \"Warning: unable to identify line terminator usage in pattern.\\n\" + (\"\\tThe problem is in the <\" + tokType.name + \"> Token Type\\n\") + (\"\\t Root cause: \" + details.errMsg + \".\\n\") + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\";\n  } else if (details.issue === lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n    return \"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" + (\"\\tThe problem is in the <\" + tokType.name + \"> Token Type\\n\") + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\";\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexports.buildLineBreakIssueMessage = buildLineBreakIssueMessage;\n\nfunction getCharCodes(charsOrCodes) {\n  var charCodes = (0, utils_1.map)(charsOrCodes, function (numOrString) {\n    if ((0, utils_1.isString)(numOrString) && numOrString.length > 0) {\n      return numOrString.charCodeAt(0);\n    } else {\n      return numOrString;\n    }\n  });\n  return charCodes;\n}\n\nfunction addToMapOfArrays(map, key, value) {\n  if (map[key] === undefined) {\n    map[key] = [value];\n  } else {\n    map[key].push(value);\n  }\n}\n\nexports.minOptimizationVal = 256;\n/**\n * We ae mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\n\nvar charCodeToOptimizedIdxMap = [];\n\nfunction charCodeToOptimizedIndex(charCode) {\n  return charCode < exports.minOptimizationVal ? charCode : charCodeToOptimizedIdxMap[charCode];\n}\n\nexports.charCodeToOptimizedIndex = charCodeToOptimizedIndex;\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\n\nfunction initCharCodeToOptimizedIndexMap() {\n  if ((0, utils_1.isEmpty)(charCodeToOptimizedIdxMap)) {\n    charCodeToOptimizedIdxMap = new Array(65536);\n\n    for (var i = 0; i < 65536; i++) {\n      /* tslint:disable */\n      charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n      /* tslint:enable */\n    }\n  }\n}","map":{"version":3,"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;;AACA;;AACA;;AA0BA;;AAYA;;AAEA,IAAMA,OAAO,GAAG,SAAhB;AACaC,uBAAe,aAAf;AACAA,gBAAQ,OAAR;AAsBFA,yBACT,OAAa,IAAIC,MAAJ,CAAW,MAAX,EAAoBC,MAAjC,KAA4C,SADnC;;AAGX,SAAgBC,aAAhB,GAA6B;AAC3BH,2BAAiB,KAAjB;AACD;;AAFDA;;AAIA,SAAgBI,YAAhB,GAA4B;AAC1BJ,2BAAiB,IAAjB;AACD;;AAFDA;;AAIA,SAAgBK,iBAAhB,CACEC,UADF,EAEEC,OAFF,EAUG;AAEDA,SAAO,GAAG,sBAASA,OAAT,EAAkB;AAC1BC,aAAS,EAAER,sBADe;AAE1BS,SAAK,EAAE,KAFmB;AAG1BC,YAAQ,EAAE,KAHgB;AAI1BC,oBAAgB,EAAE,MAJQ;AAK1BC,4BAAwB,EAAE,CAAC,IAAD,EAAO,IAAP,CALA;AAM1BC,UAAM,EAAE,gBAACC,GAAD,EAAMC,MAAN,EAAY;AAAK,mBAAM,EAAN;AAAQ;AANP,GAAlB,CAAV;AASA,MAAMF,MAAM,GAAGN,OAAO,CAACM,MAAvB;AAEAA,QAAM,CAAC,iCAAD,EAAoC;AACxCG,mCAA+B;AAChC,GAFK,CAAN;AAIA,MAAIC,iBAAJ;AACAJ,QAAM,CAAC,iBAAD,EAAoB;AACxBI,qBAAiB,GAAG,oBAAOX,UAAP,EAAmB,UAACY,QAAD,EAAS;AAC9C,aAAOA,QAAQ,CAACnB,OAAD,CAAR,KAAsBoB,qBAAMC,EAAnC;AACD,KAFmB,CAApB;AAGD,GAJK,CAAN;AAMA,MAAIC,SAAS,GAAG,KAAhB;AACA,MAAIC,sBAAJ;AACAT,QAAM,CAAC,oBAAD,EAAuB;AAC3BQ,aAAS,GAAG,KAAZ;AACAC,0BAAsB,GAAG,iBAAIL,iBAAJ,EAAuB,UAACC,QAAD,EAAS;AACvD,UAAMK,WAAW,GAAGL,QAAQ,CAACnB,OAAD,CAA5B;AAEA;;AACA,UAAI,sBAASwB,WAAT,CAAJ,EAA2B;AACzB,YAAMC,YAAY,GAAGD,WAAW,CAACE,MAAjC;;AACA,YACED,YAAY,CAACE,MAAb,KAAwB,CAAxB,IACA;AACAF,oBAAY,KAAK,GAFjB,IAGAA,YAAY,KAAK,GAHjB,IAIAA,YAAY,KAAK,GAJjB,IAKA,CAACD,WAAW,CAACI,UANf,EAOE;AACA,iBAAOH,YAAP;AACD,SATD,MASO,IACLA,YAAY,CAACE,MAAb,KAAwB,CAAxB,IACAF,YAAY,CAAC,CAAD,CAAZ,KAAoB,IADpB,IAEA;AACA,SAAC,sBACC,CACE,GADF,EAEE,GAFF,EAGE,GAHF,EAIE,GAJF,EAKE,GALF,EAME,GANF,EAOE,GAPF,EAQE,GARF,EASE,GATF,EAUE,GAVF,EAWE,GAXF,EAYE,GAZF,EAaE,GAbF,EAcE,GAdF,EAeE,GAfF,EAgBE,GAhBF,CADD,EAmBCA,YAAY,CAAC,CAAD,CAnBb,CAJI,EAyBL;AACA;AACA;AACA;AACA,iBAAOA,YAAY,CAAC,CAAD,CAAnB;AACD,SA9BM,MA8BA;AACL,iBAAOjB,OAAO,CAACC,SAAR,GACHoB,aAAa,CAACL,WAAD,CADV,GAEHM,eAAe,CAACN,WAAD,CAFnB;AAGD;AACF,OA9CD,MA8CO,IAAI,wBAAWA,WAAX,CAAJ,EAA6B;AAClCF,iBAAS,GAAG,IAAZ,CADkC,CAElC;;AACA,eAAO;AAAES,cAAI,EAAEP;AAAR,SAAP;AACD,OAJM,MAIA,IAAI,iBAAIA,WAAJ,EAAiB,MAAjB,CAAJ,EAA8B;AACnCF,iBAAS,GAAG,IAAZ,CADmC,CAEnC;;AACA,eAAOE,WAAP;AACD,OAJM,MAIA,IAAI,OAAOA,WAAP,KAAuB,QAA3B,EAAqC;AAC1C,YAAIA,WAAW,CAACG,MAAZ,KAAuB,CAA3B,EAA8B;AAC5B,iBAAOH,WAAP;AACD,SAFD,MAEO;AACL,cAAMQ,mBAAmB,GAAGR,WAAW,CAACS,OAAZ,CAC1B,qBAD0B,EAE1B,MAF0B,CAA5B;AAIA,cAAMC,aAAa,GAAG,IAAIhC,MAAJ,CAAW8B,mBAAX,CAAtB;AACA,iBAAOxB,OAAO,CAACC,SAAR,GACHoB,aAAa,CAACK,aAAD,CADV,GAEHJ,eAAe,CAACI,aAAD,CAFnB;AAGD;AACF,OAbM,MAaA;AACL,cAAMC,KAAK,CAAC,sBAAD,CAAX;AACD;AACF,KA1EwB,CAAzB;AA2ED,GA7EK,CAAN;AA+EA,MAAIC,gBAAJ;AACA,MAAIC,iBAAJ;AACA,MAAIC,2BAAJ;AACA,MAAIC,oBAAJ;AACA,MAAIC,mBAAJ;AACA1B,QAAM,CAAC,cAAD,EAAiB;AACrBsB,oBAAgB,GAAG,iBACjBlB,iBADiB,EAEjB,UAACC,QAAD,EAAS;AAAK,qBAAQ,CAACsB,YAAT;AAAqB,KAFlB,CAAnB;AAKAJ,qBAAiB,GAAG,iBAAInB,iBAAJ,EAAuB,UAACwB,KAAD,EAAW;AACpD,UAAMC,SAAS,GAAGD,KAAK,CAACE,KAAxB;AACA;;AACA,UAAID,SAAS,KAAKvB,qBAAMyB,OAAxB,EAAiC;AAC/B,eAAOC,SAAP;AACD,OAFD,MAEO,IAAI,sBAASH,SAAT,CAAJ,EAAyB;AAC9B,eAAOA,SAAP;AACD,OAFM,MAEA,IAAI,yBAAYA,SAAZ,CAAJ,EAA4B;AACjC,eAAO,KAAP;AACD,OAFM,MAEA;AACL,cAAMR,KAAK,CAAC,sBAAD,CAAX;AACD;AACF,KAZmB,CAApB;AAcAG,+BAA2B,GAAG,iBAAIpB,iBAAJ,EAAuB,UAACwB,KAAD,EAAW;AAC9D,UAAMK,aAAa,GAAGL,KAAK,CAACM,UAA5B;;AAEA,UAAID,aAAJ,EAAmB;AACjB,YAAME,eAAe,GAAG,qBAAQF,aAAR,IACpB,iBAAIA,aAAJ,EAAmB,UAACG,IAAD,EAAU;AAAK,sCAAQhC,iBAAR,EAA2BgC,IAA3B;AAAgC,SAAlE,CADoB,GAEpB,CAAC,qBAAQhC,iBAAR,EAA2B6B,aAA3B,CAAD,CAFJ;AAGA,eAAOE,eAAP;AACD;AACF,KAT6B,CAA9B;AAWAV,wBAAoB,GAAG,iBACrBrB,iBADqB,EAErB,UAACwB,KAAD,EAAW;AAAK,kBAAK,CAACS,SAAN;AAAe,KAFV,CAAvB;AAKAX,uBAAmB,GAAG,iBAAItB,iBAAJ,EAAuB,UAACwB,KAAD,EAAW;AACtD,8BAAIA,KAAJ,EAAW,UAAX;AAAsB,KADF,CAAtB;AAGD,GAvCK,CAAN;AAyCA,MAAIU,6BAAJ;AACAtC,QAAM,CAAC,0BAAD,EAA6B;AACjC,QAAMuC,uBAAuB,GAAGC,YAAY,CAC1C9C,OAAO,CAACK,wBADkC,CAA5C;AAGAuC,iCAA6B,GAAG,iBAAIlC,iBAAJ,EAAuB,UAACqC,OAAD,EAAQ;AAAK;AAAK,KAAzC,CAAhC;;AACA,QAAI/C,OAAO,CAACI,gBAAR,KAA6B,YAAjC,EAA+C;AAC7CwC,mCAA6B,GAAG,iBAAIlC,iBAAJ,EAAuB,UAACqC,OAAD,EAAQ;AAC7D,YAAI,iBAAIA,OAAJ,EAAa,aAAb,CAAJ,EAAiC;AAC/B,iBAAOA,OAAO,CAACC,WAAf;AACD,SAFD,MAEO;AACL,cACEC,qBAAqB,CAACF,OAAD,EAAUF,uBAAV,CAArB,KAA4D,KAD9D,EAEE;AACA,mBAAO,gCAAiBA,uBAAjB,EAA0CE,OAAO,CAACvD,OAAlD,CAAP;AACD;AACF;AACF,OAV+B,CAAhC;AAWD;AACF,GAlBK,CAAN;AAoBA,MAAI0D,oBAAJ;AACA,MAAIC,iBAAJ;AACA,MAAIC,WAAJ;AACA,MAAIC,kBAAJ;AACA/C,QAAM,CAAC,iBAAD,EAAoB;AACxB4C,wBAAoB,GAAG,iBAAIxC,iBAAJ,EAAuB4C,eAAvB,CAAvB;AACAH,qBAAiB,GAAG,iBAAIpC,sBAAJ,EAA4BwC,cAA5B,CAApB;AAEAH,eAAW,GAAG,oBACZ1C,iBADY,EAEZ,UAAC8C,GAAD,EAAMtB,KAAN,EAAgB;AACd,UAAMC,SAAS,GAAGD,KAAK,CAACE,KAAxB;;AACA,UAAI,sBAASD,SAAT,KAAuB,EAAEA,SAAS,KAAKvB,qBAAMyB,OAAtB,CAA3B,EAA2D;AACzDmB,WAAG,CAACrB,SAAD,CAAH,GAAiB,EAAjB;AACD;;AACD,aAAOqB,GAAP;AACD,KARW,EASZ,EATY,CAAd;AAYAH,sBAAkB,GAAG,iBAAItC,sBAAJ,EAA4B,UAAC0C,CAAD,EAAIC,GAAJ,EAAO;AACtD,aAAO;AACLC,eAAO,EAAE5C,sBAAsB,CAAC2C,GAAD,CAD1B;AAELE,iBAAS,EAAE9B,2BAA2B,CAAC4B,GAAD,CAFjC;AAGLG,yBAAiB,EAAEjB,6BAA6B,CAACc,GAAD,CAH3C;AAILI,gBAAQ,EAAEZ,oBAAoB,CAACQ,GAAD,CAJzB;AAKLK,aAAK,EAAEZ,iBAAiB,CAACO,GAAD,CALnB;AAMLM,aAAK,EAAEnC,iBAAiB,CAAC6B,GAAD,CANnB;AAOLO,YAAI,EAAElC,oBAAoB,CAAC2B,GAAD,CAPrB;AAQLQ,WAAG,EAAElC,mBAAmB,CAAC0B,GAAD,CARnB;AASLzB,oBAAY,EAAEL,gBAAgB,CAAC8B,GAAD,CATzB;AAULS,iBAAS,EAAEzD,iBAAiB,CAACgD,GAAD;AAVvB,OAAP;AAYD,KAboB,CAArB;AAcD,GA9BK,CAAN;AAgCA,MAAIU,cAAc,GAAG,IAArB;AACA,MAAIC,4BAA4B,GAAG,EAAnC;;AAEA,MAAI,CAACrE,OAAO,CAACG,QAAb,EAAuB;AACrBG,UAAM,CAAC,yBAAD,EAA4B;AAChC+D,kCAA4B,GAAG,oBAC7B3D,iBAD6B,EAE7B,UAAC4D,MAAD,EAASC,WAAT,EAAsBb,GAAtB,EAAyB;AACvB,YAAI,OAAOa,WAAW,CAAC/E,OAAnB,KAA+B,QAAnC,EAA6C;AAC3C,cAAMgF,QAAQ,GAAGD,WAAW,CAAC/E,OAAZ,CAAoBiF,UAApB,CAA+B,CAA/B,CAAjB;AACA,cAAMC,YAAY,GAAGC,wBAAwB,CAACH,QAAD,CAA7C;AACAI,0BAAgB,CAACN,MAAD,EAASI,YAAT,EAAuBrB,kBAAkB,CAACK,GAAD,CAAzC,CAAhB;AACD,SAJD,MAIO,IAAI,qBAAQa,WAAW,CAACM,gBAApB,CAAJ,EAA2C;AAChD,cAAIC,kBAAJ;AACA,+BAAQP,WAAW,CAACM,gBAApB,EAAsC,UAACE,SAAD,EAAU;AAC9C,gBAAMP,QAAQ,GACZ,OAAOO,SAAP,KAAqB,QAArB,GACIA,SAAS,CAACN,UAAV,CAAqB,CAArB,CADJ,GAEIM,SAHN;AAIA,gBAAMC,gBAAgB,GAAGL,wBAAwB,CAACH,QAAD,CAAjD,CAL8C,CAM9C;;AACA;AACA;AACA;;AACA,gBAAIM,kBAAgB,KAAKE,gBAAzB,EAA2C;AACzCF,gCAAgB,GAAGE,gBAAnB;AACAJ,8BAAgB,CACdN,MADc,EAEdU,gBAFc,EAGd3B,kBAAkB,CAACK,GAAD,CAHJ,CAAhB;AAKD;AACF,WAlBD;AAmBD,SArBM,MAqBA,IAAI,sBAASa,WAAW,CAAC/E,OAArB,CAAJ,EAAmC;AACxC,cAAI+E,WAAW,CAAC/E,OAAZ,CAAoByF,OAAxB,EAAiC;AAC/Bb,0BAAc,GAAG,KAAjB;;AACA,gBAAIpE,OAAO,CAACkF,mBAAZ,EAAiC;AAC/B,uCACE,KAAGC,qCAAH,IACE,2BAAyBZ,WAAW,CAAC/E,OAAZ,CAAoB4F,QAApB,EAAzB,GAAuD,eADzD,IAEE,sFAFF,GAGE,6DAHF,GAIE,kGALJ;AAOD;AACF,WAXD,MAWO;AACL,gBAAMC,cAAc,GAAG,6CACrBd,WAAW,CAAC/E,OADS,EAErBQ,OAAO,CAACkF,mBAFa,CAAvB;AAIA;AACA;AACA;;AACA,gBAAI,qBAAQG,cAAR,CAAJ,EAA6B;AAC3B;AACA;AACA;AACAjB,4BAAc,GAAG,KAAjB;AACD;;AACD,iCAAQiB,cAAR,EAAwB,UAACC,IAAD,EAAK;AAC3BV,8BAAgB,CAACN,MAAD,EAASgB,IAAT,EAAejC,kBAAkB,CAACK,GAAD,CAAjC,CAAhB;AACD,aAFD;AAGD;AACF,SA9BM,MA8BA;AACL,cAAI1D,OAAO,CAACkF,mBAAZ,EAAiC;AAC/B,qCACE,KAAGC,qCAAH,IACE,mBAAiBZ,WAAW,CAACgB,IAA7B,GAAiC,qFADnC,IAEE,6DAFF,GAGE,iGAJJ;AAMD;;AACDnB,wBAAc,GAAG,KAAjB;AACD;;AAED,eAAOE,MAAP;AACD,OAvE4B,EAwE7B,EAxE6B,CAA/B;AA0ED,KA3EK,CAAN;AA4ED;;AACDhE,QAAM,CAAC,cAAD,EAAiB;AACrB+D,gCAA4B,GAAG,uBAAUA,4BAAV,CAA/B;AACD,GAFK,CAAN;AAIA,SAAO;AACLjB,eAAW,EAAEA,WADR;AAELC,sBAAkB,EAAEA,kBAFf;AAGLgB,gCAA4B,EAAEA,4BAHzB;AAILvD,aAAS,EAAEA,SAJN;AAKLsD,kBAAc,EAAEA;AALX,GAAP;AAOD;;AAtTD3E;;AAwTA,SAAgB+F,gBAAhB,CACEzF,UADF,EAEE0F,eAFF,EAE2B;AAEzB,MAAIC,MAAM,GAAG,EAAb;AAEA,MAAMC,aAAa,GAAGC,mBAAmB,CAAC7F,UAAD,CAAzC;AACA2F,QAAM,GAAGA,MAAM,CAACG,MAAP,CAAcF,aAAa,CAACD,MAA5B,CAAT;AAEA,MAAMI,aAAa,GAAGC,mBAAmB,CAACJ,aAAa,CAACK,KAAf,CAAzC;AACA,MAAMC,eAAe,GAAGH,aAAa,CAACE,KAAtC;AACAN,QAAM,GAAGA,MAAM,CAACG,MAAP,CAAcC,aAAa,CAACJ,MAA5B,CAAT;AAEAA,QAAM,GAAGA,MAAM,CAACG,MAAP,CAAcK,qBAAqB,CAACD,eAAD,CAAnC,CAAT;AAEAP,QAAM,GAAGA,MAAM,CAACG,MAAP,CAAcM,oBAAoB,CAACF,eAAD,CAAlC,CAAT;AAEAP,QAAM,GAAGA,MAAM,CAACG,MAAP,CACPO,uBAAuB,CAACH,eAAD,EAAkBR,eAAlB,CADhB,CAAT;AAIAC,QAAM,GAAGA,MAAM,CAACG,MAAP,CAAcQ,uBAAuB,CAACJ,eAAD,CAArC,CAAT;AAEA,SAAOP,MAAP;AACD;;AAxBDjG;;AA0BA,SAASyG,qBAAT,CACEnG,UADF,EACyB;AAEvB,MAAI2F,MAAM,GAAG,EAAb;AACA,MAAMY,kBAAkB,GAAG,oBAAOvG,UAAP,EAAmB,UAACwE,WAAD,EAAY;AACxD,iCAASA,WAAW,CAAC/E,OAAD,CAApB;AAA8B,GADL,CAA3B;AAIAkG,QAAM,GAAGA,MAAM,CAACG,MAAP,CAAcU,oBAAoB,CAACD,kBAAD,CAAlC,CAAT;AAEAZ,QAAM,GAAGA,MAAM,CAACG,MAAP,CAAcW,sBAAsB,CAACF,kBAAD,CAApC,CAAT;AAEAZ,QAAM,GAAGA,MAAM,CAACG,MAAP,CAAcY,oBAAoB,CAACH,kBAAD,CAAlC,CAAT;AAEAZ,QAAM,GAAGA,MAAM,CAACG,MAAP,CAAca,qBAAqB,CAACJ,kBAAD,CAAnC,CAAT;AAEAZ,QAAM,GAAGA,MAAM,CAACG,MAAP,CAAcc,qBAAqB,CAACL,kBAAD,CAAnC,CAAT;AAEA,SAAOZ,MAAP;AACD;;AAOD,SAAgBE,mBAAhB,CACE7F,UADF,EACyB;AAEvB,MAAM6G,4BAA4B,GAAG,oBAAO7G,UAAP,EAAmB,UAACY,QAAD,EAAS;AAC/D,WAAO,CAAC,iBAAIA,QAAJ,EAAcnB,OAAd,CAAR;AACD,GAFoC,CAArC;AAIA,MAAMkG,MAAM,GAAG,iBAAIkB,4BAAJ,EAAkC,UAACjG,QAAD,EAAS;AACxD,WAAO;AACLkG,aAAO,EACL,mBACAlG,QAAQ,CAAC4E,IADT,GAEA,sCAJG;AAKL7C,UAAI,EAAE9B,wCAAyBkG,eAL1B;AAML/G,gBAAU,EAAE,CAACY,QAAD;AANP,KAAP;AAQD,GATc,CAAf;AAWA,MAAMqF,KAAK,GAAG,wBAAWjG,UAAX,EAAuB6G,4BAAvB,CAAd;AACA,SAAO;AAAElB,UAAM,QAAR;AAAUM,SAAK;AAAf,GAAP;AACD;;AApBDvG;;AAsBA,SAAgBsG,mBAAhB,CACEhG,UADF,EACyB;AAEvB,MAAMgH,4BAA4B,GAAG,oBAAOhH,UAAP,EAAmB,UAACY,QAAD,EAAS;AAC/D,QAAMgD,OAAO,GAAGhD,QAAQ,CAACnB,OAAD,CAAxB;AACA,WACE,CAAC,sBAASmE,OAAT,CAAD,IACA,CAAC,wBAAWA,OAAX,CADD,IAEA,CAAC,iBAAIA,OAAJ,EAAa,MAAb,CAFD,IAGA,CAAC,sBAASA,OAAT,CAJH;AAMD,GARoC,CAArC;AAUA,MAAM+B,MAAM,GAAG,iBAAIqB,4BAAJ,EAAkC,UAACpG,QAAD,EAAS;AACxD,WAAO;AACLkG,aAAO,EACL,mBACAlG,QAAQ,CAAC4E,IADT,GAEA,6CAFA,GAGA,8GALG;AAML7C,UAAI,EAAE9B,wCAAyBoG,eAN1B;AAOLjH,gBAAU,EAAE,CAACY,QAAD;AAPP,KAAP;AASD,GAVc,CAAf;AAYA,MAAMqF,KAAK,GAAG,wBAAWjG,UAAX,EAAuBgH,4BAAvB,CAAd;AACA,SAAO;AAAErB,UAAM,QAAR;AAAUM,SAAK;AAAf,GAAP;AACD;;AA3BDvG;AA6BA,IAAMwH,YAAY,GAAG,WAArB;;AAEA,SAAgBV,oBAAhB,CACExG,UADF,EACyB;AAEvB;AAAA;AAAA;AAA8BmH;;AAA9B;AAAA;;AACEC,oBAAQ,KAAR;;AAKD;;AAHCC,yDAAeC,IAAf,EAAmB;AACjB,WAAKC,KAAL,GAAa,IAAb;AACD,KAFD;;AAGF;AANA,IAA8BC,iCAA9B;;AAQA,MAAMC,YAAY,GAAG,oBAAOzH,UAAP,EAAmB,UAACY,QAAD,EAAS;AAC/C,QAAMgD,OAAO,GAAGhD,QAAQ,CAACnB,OAAD,CAAxB;;AAEA,QAAI;AACF,UAAMiI,SAAS,GAAG,mCAAa9D,OAAb,CAAlB;AACA,UAAM+D,gBAAgB,GAAG,IAAIN,eAAJ,EAAzB;AACAM,sBAAgB,CAACC,KAAjB,CAAuBF,SAAvB;AAEA,aAAOC,gBAAgB,CAACJ,KAAxB;AACD,KAND,CAME,OAAOM,CAAP,EAAU;AACV;;AACA;AACA,aAAOX,YAAY,CAACY,IAAb,CAAkBlE,OAAO,CAACzC,MAA1B,CAAP;AACD;AACF,GAdoB,CAArB;AAgBA,MAAMwE,MAAM,GAAG,iBAAI8B,YAAJ,EAAkB,UAAC7G,QAAD,EAAS;AACxC,WAAO;AACLkG,aAAO,EACL,sCACA,kBADA,GAEAlG,QAAQ,CAAC4E,IAFT,GAGA,8DAHA,GAIA,oEAJA,GAKA,gBAPG;AAQL7C,UAAI,EAAE9B,wCAAyBkH,gBAR1B;AASL/H,gBAAU,EAAE,CAACY,QAAD;AATP,KAAP;AAWD,GAZc,CAAf;AAcA,SAAO+E,MAAP;AACD;;AA1CDjG;;AA4CA,SAAgBkH,qBAAhB,CACE5G,UADF,EACyB;AAEvB,MAAMgI,kBAAkB,GAAG,oBAAOhI,UAAP,EAAmB,UAACY,QAAD,EAAS;AACrD,QAAMgD,OAAO,GAAGhD,QAAQ,CAACnB,OAAD,CAAxB;AACA,WAAOmE,OAAO,CAACkE,IAAR,CAAa,EAAb,CAAP;AACD,GAH0B,CAA3B;AAKA,MAAMnC,MAAM,GAAG,iBAAIqC,kBAAJ,EAAwB,UAACpH,QAAD,EAAS;AAC9C,WAAO;AACLkG,aAAO,EACL,mBACAlG,QAAQ,CAAC4E,IADT,GAEA,oDAJG;AAKL7C,UAAI,EAAE9B,wCAAyBoH,mBAL1B;AAMLjI,gBAAU,EAAE,CAACY,QAAD;AANP,KAAP;AAQD,GATc,CAAf;AAWA,SAAO+E,MAAP;AACD;;AApBDjG;AAsBA,IAAMwI,cAAc,GAAG,gBAAvB;;AAEA,SAAgBzB,sBAAhB,CACEzG,UADF,EACyB;AAEvB;AAAA;AAAA;AAAgCmH;;AAAhC;AAAA;;AACEC,oBAAQ,KAAR;;AAKD;;AAHCe,6DAAiBb,IAAjB,EAAqB;AACnB,WAAKC,KAAL,GAAa,IAAb;AACD,KAFD;;AAGF;AANA,IAAgCC,iCAAhC;;AAQA,MAAMC,YAAY,GAAG,oBAAOzH,UAAP,EAAmB,UAACY,QAAD,EAAS;AAC/C,QAAMgD,OAAO,GAAGhD,QAAQ,CAACnB,OAAD,CAAxB;;AACA,QAAI;AACF,UAAMiI,SAAS,GAAG,mCAAa9D,OAAb,CAAlB;AACA,UAAMwE,kBAAkB,GAAG,IAAID,iBAAJ,EAA3B;AACAC,wBAAkB,CAACR,KAAnB,CAAyBF,SAAzB;AAEA,aAAOU,kBAAkB,CAACb,KAA1B;AACD,KAND,CAME,OAAOM,CAAP,EAAU;AACV;;AACA;AACA,aAAOK,cAAc,CAACJ,IAAf,CAAoBlE,OAAO,CAACzC,MAA5B,CAAP;AACD;AACF,GAboB,CAArB;AAeA,MAAMwE,MAAM,GAAG,iBAAI8B,YAAJ,EAAkB,UAAC7G,QAAD,EAAS;AACxC,WAAO;AACLkG,aAAO,EACL,sCACA,kBADA,GAEAlG,QAAQ,CAAC4E,IAFT,GAGA,gEAHA,GAIA,4EAJA,GAKA,gBAPG;AAQL7C,UAAI,EAAE9B,wCAAyBwH,gBAR1B;AASLrI,gBAAU,EAAE,CAACY,QAAD;AATP,KAAP;AAWD,GAZc,CAAf;AAcA,SAAO+E,MAAP;AACD;;AAzCDjG;;AA2CA,SAAgBgH,oBAAhB,CACE1G,UADF,EACyB;AAEvB,MAAMsI,YAAY,GAAG,oBAAOtI,UAAP,EAAmB,UAACY,QAAD,EAAS;AAC/C,QAAMgD,OAAO,GAAGhD,QAAQ,CAACnB,OAAD,CAAxB;AACA,WAAOmE,OAAO,YAAYjE,MAAnB,KAA8BiE,OAAO,CAAC2E,SAAR,IAAqB3E,OAAO,CAAC4E,MAA3D,CAAP;AACD,GAHoB,CAArB;AAKA,MAAM7C,MAAM,GAAG,iBAAI2C,YAAJ,EAAkB,UAAC1H,QAAD,EAAS;AACxC,WAAO;AACLkG,aAAO,EACL,mBACAlG,QAAQ,CAAC4E,IADT,GAEA,mEAJG;AAKL7C,UAAI,EAAE9B,wCAAyB4H,uBAL1B;AAMLzI,gBAAU,EAAE,CAACY,QAAD;AANP,KAAP;AAQD,GATc,CAAf;AAWA,SAAO+E,MAAP;AACD;;AApBDjG,oD,CAsBA;;AACA,SAAgBiH,qBAAhB,CACE3G,UADF,EACyB;AAEvB,MAAMuH,KAAK,GAAG,EAAd;AACA,MAAImB,iBAAiB,GAAG,iBAAI1I,UAAJ,EAAgB,UAAC2I,SAAD,EAAe;AACrD,WAAO,oBACL3I,UADK,EAEL,UAACuE,MAAD,EAASqE,SAAT,EAAuB;AACrB,UACED,SAAS,CAAClJ,OAAV,CAAkB0B,MAAlB,KAA6ByH,SAAS,CAACnJ,OAAV,CAAkB0B,MAA/C,IACA,CAAC,sBAASoG,KAAT,EAAgBqB,SAAhB,CADD,IAEAA,SAAS,CAACnJ,OAAV,KAAsBoB,qBAAMC,EAH9B,EAIE;AACA;AACA;AACAyG,aAAK,CAACrD,IAAN,CAAW0E,SAAX;AACArE,cAAM,CAACL,IAAP,CAAY0E,SAAZ;AACA,eAAOrE,MAAP;AACD;;AACD,aAAOA,MAAP;AACD,KAfI,EAgBL,EAhBK,CAAP;AAkBD,GAnBuB,CAAxB;AAqBAmE,mBAAiB,GAAG,qBAAQA,iBAAR,CAApB;AAEA,MAAMG,iBAAiB,GAAG,oBAAOH,iBAAP,EAA0B,UAACI,gBAAD,EAAiB;AACnE,WAAOA,gBAAgB,CAAC1H,MAAjB,GAA0B,CAAjC;AACD,GAFyB,CAA1B;AAIA,MAAMuE,MAAM,GAAG,iBAAIkD,iBAAJ,EAAuB,UAACE,cAAD,EAAoB;AACxD,QAAMC,cAAc,GAAG,iBAAID,cAAJ,EAAoB,UAACnI,QAAD,EAAc;AACvD,aAAOA,QAAQ,CAAC4E,IAAhB;AACD,KAFsB,CAAvB;AAIA,QAAMyD,aAAa,GAAS,mBAAMF,cAAN,EAAuBtJ,OAAnD;AACA,WAAO;AACLqH,aAAO,EACL,+BAA6BmC,aAA7B,GAA0C,IAA1C,IACA,wDAAsDD,cAAc,CAACE,IAAf,CACpD,IADoD,CAAtD,GAEC,KAHD,CAFG;AAMLvG,UAAI,EAAE9B,wCAAyBsI,wBAN1B;AAOLnJ,gBAAU,EAAE+I;AAPP,KAAP;AASD,GAfc,CAAf;AAiBA,SAAOpD,MAAP;AACD;;AAjDDjG;;AAmDA,SAAgB0G,oBAAhB,CACEpG,UADF,EACyB;AAEvB,MAAMoJ,YAAY,GAAG,oBAAOpJ,UAAP,EAAmB,UAACmC,KAAD,EAAW;AACjD,QAAI,CAAC,iBAAIA,KAAJ,EAAW,OAAX,CAAL,EAA0B;AACxB,aAAO,KAAP;AACD;;AACD,QAAM8B,KAAK,GAAG9B,KAAK,CAACE,KAApB;AAEA,WAAO4B,KAAK,KAAKpD,qBAAMyB,OAAhB,IAA2B2B,KAAK,KAAKpD,qBAAMC,EAA3C,IAAiD,CAAC,sBAASmD,KAAT,CAAzD;AACD,GAPoB,CAArB;AASA,MAAM0B,MAAM,GAAG,iBAAIyD,YAAJ,EAAkB,UAACxI,QAAD,EAAS;AACxC,WAAO;AACLkG,aAAO,EACL,mBACAlG,QAAQ,CAAC4E,IADT,GAEA,+DAJG;AAKL7C,UAAI,EAAE9B,wCAAyBwI,wBAL1B;AAMLrJ,gBAAU,EAAE,CAACY,QAAD;AANP,KAAP;AAQD,GATc,CAAf;AAWA,SAAO+E,MAAP;AACD;;AAxBDjG;;AA0BA,SAAgB2G,uBAAhB,CACErG,UADF,EAEEsJ,UAFF,EAEsB;AAEpB,MAAMC,YAAY,GAAG,oBAAOvJ,UAAP,EAAmB,UAACmC,KAAD,EAAW;AACjD,WACEA,KAAK,CAACS,SAAN,KAAoBL,SAApB,IAAiC,CAAC,sBAAS+G,UAAT,EAAqBnH,KAAK,CAACS,SAA3B,CADpC;AAGD,GAJoB,CAArB;AAMA,MAAM+C,MAAM,GAAG,iBAAI4D,YAAJ,EAAkB,UAACvG,OAAD,EAAQ;AACvC,QAAMxC,GAAG,GACP,mBAAiBwC,OAAO,CAACwC,IAAzB,GAA6B,6DAA7B,GAA2FxC,OAAO,CAACJ,SAAnG,GAA4G,IAA5G,GACA,sBAFF;AAGA,WAAO;AACLkE,aAAO,EAAEtG,GADJ;AAELmC,UAAI,EAAE9B,wCAAyB2I,wBAF1B;AAGLxJ,gBAAU,EAAE,CAACgD,OAAD;AAHP,KAAP;AAKD,GATc,CAAf;AAWA,SAAO2C,MAAP;AACD;;AAtBDjG;;AAwBA,SAAgB4G,uBAAhB,CACEtG,UADF,EACyB;AAEvB,MAAM2F,MAAM,GAAG,EAAf;AAEA,MAAM8D,WAAW,GAAG,oBAClBzJ,UADkB,EAElB,UAACuE,MAAD,EAASvB,OAAT,EAAkBW,GAAlB,EAAqB;AACnB,QAAMC,OAAO,GAAGZ,OAAO,CAACvD,OAAxB;;AAEA,QAAImE,OAAO,KAAK/C,qBAAMC,EAAtB,EAA0B;AACxB,aAAOyD,MAAP;AACD,KALkB,CAOnB;AACA;;;AACA,QAAI,sBAASX,OAAT,CAAJ,EAAuB;AACrBW,YAAM,CAACL,IAAP,CAAY;AAAEwF,WAAG,EAAE9F,OAAP;AAAgBD,WAAG,KAAnB;AAAqBS,iBAAS,EAAEpB;AAAhC,OAAZ;AACD,KAFD,MAEO,IAAI,sBAASY,OAAT,KAAqB+F,UAAU,CAAC/F,OAAD,CAAnC,EAA8C;AACnDW,YAAM,CAACL,IAAP,CAAY;AAAEwF,WAAG,EAAE9F,OAAO,CAACzC,MAAf;AAAuBwC,WAAG,KAA1B;AAA4BS,iBAAS,EAAEpB;AAAvC,OAAZ;AACD;;AACD,WAAOuB,MAAP;AACD,GAjBiB,EAkBlB,EAlBkB,CAApB;AAqBA,uBAAQvE,UAAR,EAAoB,UAACgD,OAAD,EAAU4G,OAAV,EAAiB;AACnC,yBAAQH,WAAR,EAAqB,UAACI,EAAD,EAAwB;UAArBH,GAAG;UAAE/F,GAAG;UAAES,SAAS;;AACzC,UAAIwF,OAAO,GAAGjG,GAAV,IAAiBmG,aAAa,CAACJ,GAAD,EAAM1G,OAAO,CAACvD,OAAd,CAAlC,EAA0D;AACxD,YAAMe,GAAG,GACP,cAAY4D,SAAS,CAACoB,IAAtB,GAA0B,4BAA1B,IACA,+CAA6CxC,OAAO,CAACwC,IAArD,GAAyD,IADzD,IAEA,8BAFA,GAGA,8EAJF;AAKAG,cAAM,CAACzB,IAAP,CAAY;AACV4C,iBAAO,EAAEtG,GADC;AAEVmC,cAAI,EAAE9B,wCAAyBkJ,mBAFrB;AAGV/J,oBAAU,EAAE,CAACgD,OAAD,EAAUoB,SAAV;AAHF,SAAZ;AAKD;AACF,KAbD;AAcD,GAfD;AAiBA,SAAOuB,MAAP;AACD;;AA5CDjG;;AA8CA,SAASoK,aAAT,CAAuBJ,GAAvB,EAAoC9F,OAApC,EAAgD;AAC9C;AACA,MAAI,sBAASA,OAAT,CAAJ,EAAuB;AACrB,QAAMoG,WAAW,GAAGpG,OAAO,CAACpC,IAAR,CAAakI,GAAb,CAApB;AACA,WAAOM,WAAW,KAAK,IAAhB,IAAwBA,WAAW,CAACC,KAAZ,KAAsB,CAArD;AACD,GAHD,MAGO,IAAI,wBAAWrG,OAAX,CAAJ,EAAyB;AAC9B;AACA,WAAOA,OAAO,CAAC8F,GAAD,EAAM,CAAN,EAAS,EAAT,EAAa,EAAb,CAAd;AACD,GAHM,MAGA,IAAI,iBAAI9F,OAAJ,EAAa,MAAb,CAAJ,EAA0B;AAC/B;AACA,WAAOA,OAAO,CAACpC,IAAR,CAAakI,GAAb,EAAkB,CAAlB,EAAqB,EAArB,EAAyB,EAAzB,CAAP;AACD,GAHM,MAGA,IAAI,OAAO9F,OAAP,KAAmB,QAAvB,EAAiC;AACtC,WAAOA,OAAO,KAAK8F,GAAnB;AACD,GAFM,MAEA;AACL,UAAM9H,KAAK,CAAC,sBAAD,CAAX;AACD;AACF;;AAED,SAAS+H,UAAT,CAAoBO,MAApB,EAAkC;AAChC;AACA,MAAMC,SAAS,GAAG,CAChB,GADgB,EAEhB,IAFgB,EAGhB,GAHgB,EAIhB,GAJgB,EAKhB,GALgB,EAMhB,GANgB,EAOhB,GAPgB,EAQhB,GARgB,EAShB,GATgB,EAUhB,GAVgB,EAWhB,GAXgB,EAYhB,GAZgB,EAahB,GAbgB,CAAlB;AAeA,SACE,kBAAKA,SAAL,EAAgB,UAACC,IAAD,EAAK;AAAK,iBAAM,CAACjJ,MAAP,CAAckJ,OAAd,CAAsBD,IAAtB,MAAgC,CAAC,CAAjC;AAAkC,GAA5D,MAAkE7H,SADpE;AAGD;;AAED,SAAgBhB,eAAhB,CAAgCqC,OAAhC,EAA+C;AAC7C,MAAM0G,KAAK,GAAG1G,OAAO,CAACvC,UAAR,GAAqB,GAArB,GAA2B,EAAzC,CAD6C,CAE7C;AACA;;AACA,SAAO,IAAI1B,MAAJ,CAAW,SAAOiE,OAAO,CAACzC,MAAf,GAAqB,GAAhC,EAAqCmJ,KAArC,CAAP;AACD;;AALD5K;;AAOA,SAAgB4B,aAAhB,CAA8BsC,OAA9B,EAA6C;AAC3C,MAAM0G,KAAK,GAAG1G,OAAO,CAACvC,UAAR,GAAqB,IAArB,GAA4B,GAA1C,CAD2C,CAE3C;AACA;;AACA,SAAO,IAAI1B,MAAJ,CAAW,KAAGiE,OAAO,CAACzC,MAAtB,EAAgCmJ,KAAhC,CAAP;AACD;;AALD5K;;AAOA,SAAgB6K,oBAAhB,CACEC,eADF,EAEEC,UAFF,EAGEnK,wBAHF,EAG+C;AAE7C,MAAMqF,MAAM,GAAG,EAAf,CAF6C,CAI7C;;AACA,MAAI,CAAC,iBAAI6E,eAAJ,EAAqB9K,oBAArB,CAAL,EAAyC;AACvCiG,UAAM,CAACzB,IAAP,CAAY;AACV4C,aAAO,EACL,wDACApH,oBADA,GAEA,gCAJQ;AAKViD,UAAI,EAAE9B,wCAAyB6J;AALrB,KAAZ;AAOD;;AACD,MAAI,CAAC,iBAAIF,eAAJ,EAAqB9K,aAArB,CAAL,EAAkC;AAChCiG,UAAM,CAACzB,IAAP,CAAY;AACV4C,aAAO,EACL,wDACApH,aADA,GAEA,gCAJQ;AAKViD,UAAI,EAAE9B,wCAAyB8J;AALrB,KAAZ;AAOD;;AAED,MACE,iBAAIH,eAAJ,EAAqB9K,aAArB,KACA,iBAAI8K,eAAJ,EAAqB9K,oBAArB,CADA,IAEA,CAAC,iBAAI8K,eAAe,CAACI,KAApB,EAA2BJ,eAAe,CAACK,WAA3C,CAHH,EAIE;AACAlF,UAAM,CAACzB,IAAP,CAAY;AACV4C,aAAO,EACL,oDAAkDpH,oBAAlD,GAA8D,KAA9D,GAAoE8K,eAAe,CAACK,WAApF,GAA+F,GAA/F,GACA,wBAHQ;AAIVlI,UAAI,EAAE9B,wCAAyBiK;AAJrB,KAAZ;AAMD;;AAED,MAAI,iBAAIN,eAAJ,EAAqB9K,aAArB,CAAJ,EAAiC;AAC/B,yBAAQ8K,eAAe,CAACI,KAAxB,EAA+B,UAACG,aAAD,EAAgBC,YAAhB,EAA4B;AACzD,2BAAQD,aAAR,EAAuB,UAACvG,WAAD,EAAcyG,OAAd,EAAqB;AAC1C,YAAI,yBAAYzG,WAAZ,CAAJ,EAA8B;AAC5BmB,gBAAM,CAACzB,IAAP,CAAY;AACV4C,mBAAO,EACL,wEACA,MAAIkE,YAAJ,GAAgB,eAAhB,GAAgCC,OAAhC,GAAuC,KADvC,CAFQ;AAIVtI,gBAAI,EAAE9B,wCAAyBqK;AAJrB,WAAZ;AAMD;AACF,OATD;AAUD,KAXD;AAYD;;AAED,SAAOvF,MAAP;AACD;;AAxDDjG;;AA0DA,SAAgByL,2BAAhB,CACEX,eADF,EAEEC,UAFF,EAGEnK,wBAHF,EAG+C;AAE7C,MAAM8K,QAAQ,GAAG,EAAjB;AACA,MAAIC,eAAe,GAAG,KAAtB;AACA,MAAMC,aAAa,GAAG,qBACpB,qBAAQ,uBAAUd,eAAe,CAACI,KAA1B,EAAiC,UAACW,QAAD,EAAS;AAAK;AAAQ,GAAvD,CAAR,CADoB,CAAtB;AAIA,MAAMC,kBAAkB,GAAG,oBACzBF,aADyB,EAEzB,UAAC1K,QAAD,EAAS;AAAK,mBAAQ,CAACnB,OAAD,CAAR,KAAsBoB,qBAAMC,EAA5B;AAA8B,GAFnB,CAA3B;AAIA,MAAM2K,mBAAmB,GAAG1I,YAAY,CAACzC,wBAAD,CAAxC;;AACA,MAAImK,UAAJ,EAAgB;AACd,yBAAQe,kBAAR,EAA4B,UAACxI,OAAD,EAAQ;AAClC,UAAM0I,SAAS,GAAGxI,qBAAqB,CAACF,OAAD,EAAUyI,mBAAV,CAAvC;;AACA,UAAIC,SAAS,KAAK,KAAlB,EAAyB;AACvB,YAAM5E,OAAO,GAAG6E,0BAA0B,CAAC3I,OAAD,EAAU0I,SAAV,CAA1C;AACA,YAAME,iBAAiB,GAAG;AACxB9E,iBAAO,SADiB;AAExBnE,cAAI,EAAE+I,SAAS,CAACG,KAFQ;AAGxBzH,mBAAS,EAAEpB;AAHa,SAA1B;AAKAoI,gBAAQ,CAAClH,IAAT,CAAc0H,iBAAd;AACD,OARD,MAQO;AACL;AACA,YAAI,iBAAI5I,OAAJ,EAAa,aAAb,CAAJ,EAAiC;AAC/B,cAAIA,OAAO,CAACC,WAAR,KAAwB,IAA5B,EAAkC;AAChCoI,2BAAe,GAAG,IAAlB;AACD;AACF,SAJD,MAIO;AACL,cAAI,gCAAiBI,mBAAjB,EAAsCzI,OAAO,CAACvD,OAA9C,CAAJ,EAA4D;AAC1D4L,2BAAe,GAAG,IAAlB;AACD;AACF;AACF;AACF,KAtBD;AAuBD;;AAED,MAAIZ,UAAU,IAAI,CAACY,eAAnB,EAAoC;AAClCD,YAAQ,CAAClH,IAAT,CAAc;AACZ4C,aAAO,EACL,qCACA,uEADA,GAEA,kFAFA,GAGA,mFAHA,GAIA,gBANU;AAOZnE,UAAI,EAAE9B,wCAAyBiL;AAPnB,KAAd;AASD;;AACD,SAAOV,QAAP;AACD;;AAtDD1L;;AAwDA,SAAgBqM,gBAAhB,CAAiC1I,WAAjC,EAEC;AACC,MAAM2I,YAAY,GAAQ,EAA1B;AACA,MAAMC,SAAS,GAAG,kBAAK5I,WAAL,CAAlB;AAEA,uBAAQ4I,SAAR,EAAmB,UAACC,OAAD,EAAQ;AACzB,QAAMC,cAAc,GAAG9I,WAAW,CAAC6I,OAAD,CAAlC;AAEA;;AACA,QAAI,qBAAQC,cAAR,CAAJ,EAA6B;AAC3BH,kBAAY,CAACE,OAAD,CAAZ,GAAwB,EAAxB;AACD,KAFD,MAEO;AACL,YAAMtK,KAAK,CAAC,sBAAD,CAAX;AACD;AACF,GATD;AAWA,SAAOoK,YAAP;AACD;;AAlBDtM,4C,CAoBA;;AACA,SAAgB6D,eAAhB,CAAgCa,SAAhC,EAA8C;AAC5C,MAAMR,OAAO,GAAGQ,SAAS,CAAC3E,OAA1B;AACA;;AACA,MAAI,sBAASmE,OAAT,CAAJ,EAAuB;AACrB,WAAO,KAAP;AACD,GAFD,MAEO,IAAI,wBAAWA,OAAX,CAAJ,EAAyB;AAC9B;AACA,WAAO,IAAP;AACD,GAHM,MAGA,IAAI,iBAAIA,OAAJ,EAAa,MAAb,CAAJ,EAA0B;AAC/B;AACA,WAAO,IAAP;AACD,GAHM,MAGA,IAAI,sBAASA,OAAT,CAAJ,EAAuB;AAC5B,WAAO,KAAP;AACD,GAFM,MAEA;AACL,UAAMhC,KAAK,CAAC,sBAAD,CAAX;AACD;AACF;;AAhBDlC;;AAkBA,SAAgB8D,cAAhB,CAA+BI,OAA/B,EAA2C;AACzC,MAAI,sBAASA,OAAT,KAAqBA,OAAO,CAACxC,MAAR,KAAmB,CAA5C,EAA+C;AAC7C,WAAOwC,OAAO,CAACc,UAAR,CAAmB,CAAnB,CAAP;AACD,GAFD,MAEO;AACL,WAAO,KAAP;AACD;AACF;;AANDhF;AAQA;;;;AAGaA,wCAAwD;AACnE;AACAoI,MAAI,EAAE,cAAUsE,IAAV,EAAc;AAClB,QAAMC,GAAG,GAAGD,IAAI,CAAChL,MAAjB;;AACA,SAAK,IAAIkL,CAAC,GAAG,KAAKC,SAAlB,EAA6BD,CAAC,GAAGD,GAAjC,EAAsCC,CAAC,EAAvC,EAA2C;AACzC,UAAME,CAAC,GAAGJ,IAAI,CAAC1H,UAAL,CAAgB4H,CAAhB,CAAV;;AACA,UAAIE,CAAC,KAAK,EAAV,EAAc;AACZ,aAAKD,SAAL,GAAiBD,CAAC,GAAG,CAArB;AACA,eAAO,IAAP;AACD,OAHD,MAGO,IAAIE,CAAC,KAAK,EAAV,EAAc;AACnB,YAAIJ,IAAI,CAAC1H,UAAL,CAAgB4H,CAAC,GAAG,CAApB,MAA2B,EAA/B,EAAmC;AACjC,eAAKC,SAAL,GAAiBD,CAAC,GAAG,CAArB;AACD,SAFD,MAEO;AACL,eAAKC,SAAL,GAAiBD,CAAC,GAAG,CAArB;AACD;;AACD,eAAO,IAAP;AACD;AACF;;AACD,WAAO,KAAP;AACD,GAnBkE;AAqBnEC,WAAS,EAAE;AArBwD,CAAxD;;AAwBb,SAASrJ,qBAAT,CACEF,OADF,EAEEF,uBAFF,EAEmC;AASjC,MAAI,iBAAIE,OAAJ,EAAa,aAAb,CAAJ,EAAiC;AAC/B;AACA;AACA,WAAO,KAAP;AACD,GAJD,MAIO;AACL;AACA,QAAI,sBAASA,OAAO,CAACvD,OAAjB,CAAJ,EAA+B;AAC7B,UAAI;AACF;AACA,wCAAiBqD,uBAAjB,EAA0CE,OAAO,CAACvD,OAAlD;AACD,OAHD,CAGE,OAAOoI,CAAP,EAAU;AACV;AACA,eAAO;AACLgE,eAAK,EAAEhL,wCAAyB4L,mBAD3B;AAELC,gBAAM,EAAE7E,CAAC,CAACf;AAFL,SAAP;AAID;;AACD,aAAO,KAAP;AACD,KAZD,MAYO,IAAI,sBAAS9D,OAAO,CAACvD,OAAjB,CAAJ,EAA+B;AACpC;AACA,aAAO,KAAP;AACD,KAHM,MAGA,IAAI8D,eAAe,CAACP,OAAD,CAAnB,EAA8B;AACnC;AACA,aAAO;AAAE6I,aAAK,EAAEhL,wCAAyB8L;AAAlC,OAAP;AACD,KAHM,MAGA;AACL,YAAM/K,KAAK,CAAC,sBAAD,CAAX;AACD;AACF;AACF;;AAED,SAAgB+J,0BAAhB,CACE3I,OADF,EAEE4J,OAFF,EAOG;AAED;AACA,MAAIA,OAAO,CAACf,KAAR,KAAkBhL,wCAAyB4L,mBAA/C,EAAoE;AAClE,WACE,qEACA,8BAA4BzJ,OAAO,CAACwC,IAApC,GAAwC,gBADxC,KAEA,oBAAkBoH,OAAO,CAACF,MAA1B,GAAgC,KAFhC,IAGA,qGAJF;AAMD,GAPD,MAOO,IAAIE,OAAO,CAACf,KAAR,KAAkBhL,wCAAyB8L,iBAA/C,EAAkE;AACvE,WACE,gFACA,8BAA4B3J,OAAO,CAACwC,IAApC,GAAwC,gBADxC,IAEA,mGAHF;AAKD,GANM,MAMA;AACL,UAAM5D,KAAK,CAAC,sBAAD,CAAX;AACD;AACF;;AA1BDlC;;AA4BA,SAASqD,YAAT,CAAsB8J,YAAtB,EAAuD;AACrD,MAAMC,SAAS,GAAG,iBAAID,YAAJ,EAAkB,UAACE,WAAD,EAAY;AAC9C,QAAI,sBAASA,WAAT,KAAyBA,WAAW,CAAC3L,MAAZ,GAAqB,CAAlD,EAAqD;AACnD,aAAO2L,WAAW,CAACrI,UAAZ,CAAuB,CAAvB,CAAP;AACD,KAFD,MAEO;AACL,aAAOqI,WAAP;AACD;AACF,GANiB,CAAlB;AAQA,SAAOD,SAAP;AACD;;AAED,SAASjI,gBAAT,CAA0BmI,GAA1B,EAA+BC,GAA/B,EAAoCC,KAApC,EAAyC;AACvC,MAAIF,GAAG,CAACC,GAAD,CAAH,KAAa1K,SAAjB,EAA4B;AAC1ByK,OAAG,CAACC,GAAD,CAAH,GAAW,CAACC,KAAD,CAAX;AACD,GAFD,MAEO;AACLF,OAAG,CAACC,GAAD,CAAH,CAAS/I,IAAT,CAAcgJ,KAAd;AACD;AACF;;AAEYxN,6BAAqB,GAArB;AAEb;;;;;;;;;;;;;;;;AAeA,IAAIyN,yBAAyB,GAAG,EAAhC;;AACA,SAAgBvI,wBAAhB,CAAyCH,QAAzC,EAAiD;AAC/C,SAAOA,QAAQ,GAAG/E,0BAAX,GACH+E,QADG,GAEH0I,yBAAyB,CAAC1I,QAAD,CAF7B;AAGD;;AAJD/E;AAMA;;;;;;;;;AAQA,SAASgB,+BAAT,GAAwC;AACtC,MAAI,qBAAQyM,yBAAR,CAAJ,EAAwC;AACtCA,6BAAyB,GAAG,IAAIC,KAAJ,CAAU,KAAV,CAA5B;;AACA,SAAK,IAAId,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAApB,EAA2BA,CAAC,EAA5B,EAAgC;AAC9B;AACAa,+BAAyB,CAACb,CAAD,CAAzB,GAA+BA,CAAC,GAAG,GAAJ,GAAU,MAAM,CAAC,EAAEA,CAAC,GAAG,GAAN,CAAjB,GAA8BA,CAA7D;AACA;AACD;AACF;AACF","names":["PATTERN","exports","RegExp","sticky","disableSticky","enableSticky","analyzeTokenTypes","tokenTypes","options","useSticky","debug","safeMode","positionTracking","lineTerminatorCharacters","tracer","msg","action","initCharCodeToOptimizedIndexMap","onlyRelevantTypes","currType","lexer_public_1","NA","hasCustom","allTransformedPatterns","currPattern","regExpSource","source","length","ignoreCase","addStickyFlag","addStartOfInput","exec","escapedRegExpString","replace","wrappedRegExp","Error","patternIdxToType","patternIdxToGroup","patternIdxToLongerAltIdxArr","patternIdxToPushMode","patternIdxToPopMode","tokenTypeIdx","clazz","groupName","GROUP","SKIPPED","undefined","longerAltType","LONGER_ALT","longerAltIdxArr","type","PUSH_MODE","patternIdxToCanLineTerminator","lineTerminatorCharCodes","getCharCodes","tokType","LINE_BREAKS","checkLineBreaksIssues","patternIdxToIsCustom","patternIdxToShort","emptyGroups","patternIdxToConfig","isCustomPattern","isShortPattern","acc","x","idx","pattern","longerAlt","canLineTerminator","isCustom","short","group","push","pop","tokenType","canBeOptimized","charCodeToPatternIdxToConfig","result","currTokType","charCode","charCodeAt","optimizedIdx","charCodeToOptimizedIndex","addToMapOfArrays","START_CHARS_HINT","lastOptimizedIdx_1","charOrInt","currOptimizedIdx","unicode","ensureOptimizations","reg_exp_1","toString","optimizedCodes","code","name","validatePatterns","validModesNames","errors","missingResult","findMissingPatterns","concat","invalidResult","findInvalidPatterns","valid","validTokenTypes","validateRegExpPattern","findInvalidGroupType","findModesThatDoNotExist","findUnreachablePatterns","withRegExpPatterns","findEndOfInputAnchor","findStartOfInputAnchor","findUnsupportedFlags","findDuplicatePatterns","findEmptyMatchRegExps","tokenTypesWithMissingPattern","message","MISSING_PATTERN","tokenTypesWithInvalidPattern","INVALID_PATTERN","end_of_input","__extends","_this","EndAnchorFinder","node","found","regexp_to_ast_1","invalidRegex","regexpAst","endAnchorVisitor","visit","e","test","EOI_ANCHOR_FOUND","matchesEmptyString","EMPTY_MATCH_PATTERN","start_of_input","StartAnchorFinder","startAnchorVisitor","SOI_ANCHOR_FOUND","invalidFlags","multiline","global","UNSUPPORTED_FLAGS_FOUND","identicalPatterns","outerType","innerType","duplicatePatterns","currIdenticalSet","setOfIdentical","tokenTypeNames","dupPatternSrc","join","DUPLICATE_PATTERNS_FOUND","invalidTypes","INVALID_GROUP_TYPE_FOUND","validModes","invalidModes","PUSH_MODE_DOES_NOT_EXIST","canBeTested","str","noMetaChar","testIdx","_a","testTokenType","UNREACHABLE_PATTERN","regExpArray","index","regExp","metaChars","char","indexOf","flags","performRuntimeChecks","lexerDefinition","trackLines","MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE","MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY","modes","defaultMode","MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST","currModeValue","currModeName","currIdx","LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED","performWarningRuntimeChecks","warnings","hasAnyLineBreak","allTokenTypes","tokTypes","concreteTokenTypes","terminatorCharCodes","currIssue","buildLineBreakIssueMessage","warningDescriptor","issue","NO_LINE_BREAKS_FLAGS","cloneEmptyGroups","clonedResult","groupKeys","currKey","currGroupValue","text","len","i","lastIndex","c","IDENTIFY_TERMINATOR","errMsg","CUSTOM_LINE_BREAK","details","charsOrCodes","charCodes","numOrString","map","key","value","charCodeToOptimizedIdxMap","Array"],"sources":["/Users/arbus/Documents/SpaceInBrowser/node_modules/chevrotain/src/scan/lexer.ts"],"sourcesContent":["import { BaseRegExpVisitor } from \"regexp-to-ast\"\nimport { IRegExpExec, Lexer, LexerDefinitionErrorType } from \"./lexer_public\"\nimport {\n  compact,\n  contains,\n  defaults,\n  difference,\n  filter,\n  find,\n  first,\n  flatten,\n  forEach,\n  has,\n  indexOf,\n  isArray,\n  isEmpty,\n  isFunction,\n  isRegExp,\n  isString,\n  isUndefined,\n  keys,\n  map,\n  mapValues,\n  packArray,\n  PRINT_ERROR,\n  reduce,\n  reject\n} from \"@chevrotain/utils\"\nimport {\n  canMatchCharCode,\n  failedOptimizationPrefixMsg,\n  getOptimizedStartCodesIndices\n} from \"./reg_exp\"\nimport {\n  ILexerDefinitionError,\n  ILineTerminatorsTester,\n  IMultiModeLexerDefinition,\n  IToken,\n  TokenType\n} from \"@chevrotain/types\"\nimport { getRegExpAst } from \"./reg_exp_parser\"\n\nconst PATTERN = \"PATTERN\"\nexport const DEFAULT_MODE = \"defaultMode\"\nexport const MODES = \"modes\"\n\nexport interface IPatternConfig {\n  pattern: IRegExpExec\n  longerAlt: number[]\n  canLineTerminator: boolean\n  isCustom: boolean\n  short: number | boolean\n  group: any\n  push: string\n  pop: boolean\n  tokenTypeIdx: number\n}\n\nexport interface IAnalyzeResult {\n  patternIdxToConfig: IPatternConfig[]\n  charCodeToPatternIdxToConfig: { [charCode: number]: IPatternConfig[] }\n  emptyGroups: { [groupName: string]: IToken[] }\n  hasCustom: boolean\n  canBeOptimized: boolean\n}\n\nexport let SUPPORT_STICKY =\n  typeof (<any>new RegExp(\"(?:)\")).sticky === \"boolean\"\n\nexport function disableSticky() {\n  SUPPORT_STICKY = false\n}\n\nexport function enableSticky() {\n  SUPPORT_STICKY = true\n}\n\nexport function analyzeTokenTypes(\n  tokenTypes: TokenType[],\n  options: {\n    positionTracking?: \"full\" | \"onlyStart\" | \"onlyOffset\"\n    ensureOptimizations?: boolean\n    lineTerminatorCharacters?: (number | string)[]\n    // TODO: should `useSticky` be an argument here?\n    useSticky?: boolean\n    safeMode?: boolean\n    tracer?: (msg: string, action: Function) => void\n  }\n): IAnalyzeResult {\n  options = defaults(options, {\n    useSticky: SUPPORT_STICKY,\n    debug: false,\n    safeMode: false,\n    positionTracking: \"full\",\n    lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n    tracer: (msg, action) => action()\n  })\n\n  const tracer = options.tracer\n\n  tracer(\"initCharCodeToOptimizedIndexMap\", () => {\n    initCharCodeToOptimizedIndexMap()\n  })\n\n  let onlyRelevantTypes\n  tracer(\"Reject Lexer.NA\", () => {\n    onlyRelevantTypes = reject(tokenTypes, (currType) => {\n      return currType[PATTERN] === Lexer.NA\n    })\n  })\n\n  let hasCustom = false\n  let allTransformedPatterns\n  tracer(\"Transform Patterns\", () => {\n    hasCustom = false\n    allTransformedPatterns = map(onlyRelevantTypes, (currType) => {\n      const currPattern = currType[PATTERN]\n\n      /* istanbul ignore else */\n      if (isRegExp(currPattern)) {\n        const regExpSource = currPattern.source\n        if (\n          regExpSource.length === 1 &&\n          // only these regExp meta characters which can appear in a length one regExp\n          regExpSource !== \"^\" &&\n          regExpSource !== \"$\" &&\n          regExpSource !== \".\" &&\n          !currPattern.ignoreCase\n        ) {\n          return regExpSource\n        } else if (\n          regExpSource.length === 2 &&\n          regExpSource[0] === \"\\\\\" &&\n          // not a meta character\n          !contains(\n            [\n              \"d\",\n              \"D\",\n              \"s\",\n              \"S\",\n              \"t\",\n              \"r\",\n              \"n\",\n              \"t\",\n              \"0\",\n              \"c\",\n              \"b\",\n              \"B\",\n              \"f\",\n              \"v\",\n              \"w\",\n              \"W\"\n            ],\n            regExpSource[1]\n          )\n        ) {\n          // escaped meta Characters: /\\+/ /\\[/\n          // or redundant escaping: /\\a/\n          // without the escaping \"\\\"\n          return regExpSource[1]\n        } else {\n          return options.useSticky\n            ? addStickyFlag(currPattern)\n            : addStartOfInput(currPattern)\n        }\n      } else if (isFunction(currPattern)) {\n        hasCustom = true\n        // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n        return { exec: currPattern }\n      } else if (has(currPattern, \"exec\")) {\n        hasCustom = true\n        // ICustomPattern\n        return currPattern\n      } else if (typeof currPattern === \"string\") {\n        if (currPattern.length === 1) {\n          return currPattern\n        } else {\n          const escapedRegExpString = currPattern.replace(\n            /[\\\\^$.*+?()[\\]{}|]/g,\n            \"\\\\$&\"\n          )\n          const wrappedRegExp = new RegExp(escapedRegExpString)\n          return options.useSticky\n            ? addStickyFlag(wrappedRegExp)\n            : addStartOfInput(wrappedRegExp)\n        }\n      } else {\n        throw Error(\"non exhaustive match\")\n      }\n    })\n  })\n\n  let patternIdxToType\n  let patternIdxToGroup\n  let patternIdxToLongerAltIdxArr\n  let patternIdxToPushMode\n  let patternIdxToPopMode\n  tracer(\"misc mapping\", () => {\n    patternIdxToType = map(\n      onlyRelevantTypes,\n      (currType) => currType.tokenTypeIdx\n    )\n\n    patternIdxToGroup = map(onlyRelevantTypes, (clazz: any) => {\n      const groupName = clazz.GROUP\n      /* istanbul ignore next */\n      if (groupName === Lexer.SKIPPED) {\n        return undefined\n      } else if (isString(groupName)) {\n        return groupName\n      } else if (isUndefined(groupName)) {\n        return false\n      } else {\n        throw Error(\"non exhaustive match\")\n      }\n    })\n\n    patternIdxToLongerAltIdxArr = map(onlyRelevantTypes, (clazz: any) => {\n      const longerAltType = clazz.LONGER_ALT\n\n      if (longerAltType) {\n        const longerAltIdxArr = isArray(longerAltType)\n          ? map(longerAltType, (type: any) => indexOf(onlyRelevantTypes, type))\n          : [indexOf(onlyRelevantTypes, longerAltType)]\n        return longerAltIdxArr\n      }\n    })\n\n    patternIdxToPushMode = map(\n      onlyRelevantTypes,\n      (clazz: any) => clazz.PUSH_MODE\n    )\n\n    patternIdxToPopMode = map(onlyRelevantTypes, (clazz: any) =>\n      has(clazz, \"POP_MODE\")\n    )\n  })\n\n  let patternIdxToCanLineTerminator\n  tracer(\"Line Terminator Handling\", () => {\n    const lineTerminatorCharCodes = getCharCodes(\n      options.lineTerminatorCharacters\n    )\n    patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => false)\n    if (options.positionTracking !== \"onlyOffset\") {\n      patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => {\n        if (has(tokType, \"LINE_BREAKS\")) {\n          return tokType.LINE_BREAKS\n        } else {\n          if (\n            checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false\n          ) {\n            return canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN)\n          }\n        }\n      })\n    }\n  })\n\n  let patternIdxToIsCustom\n  let patternIdxToShort\n  let emptyGroups\n  let patternIdxToConfig\n  tracer(\"Misc Mapping #2\", () => {\n    patternIdxToIsCustom = map(onlyRelevantTypes, isCustomPattern)\n    patternIdxToShort = map(allTransformedPatterns, isShortPattern)\n\n    emptyGroups = reduce(\n      onlyRelevantTypes,\n      (acc, clazz: any) => {\n        const groupName = clazz.GROUP\n        if (isString(groupName) && !(groupName === Lexer.SKIPPED)) {\n          acc[groupName] = []\n        }\n        return acc\n      },\n      {}\n    )\n\n    patternIdxToConfig = map(allTransformedPatterns, (x, idx) => {\n      return {\n        pattern: allTransformedPatterns[idx],\n        longerAlt: patternIdxToLongerAltIdxArr[idx],\n        canLineTerminator: patternIdxToCanLineTerminator[idx],\n        isCustom: patternIdxToIsCustom[idx],\n        short: patternIdxToShort[idx],\n        group: patternIdxToGroup[idx],\n        push: patternIdxToPushMode[idx],\n        pop: patternIdxToPopMode[idx],\n        tokenTypeIdx: patternIdxToType[idx],\n        tokenType: onlyRelevantTypes[idx]\n      }\n    })\n  })\n\n  let canBeOptimized = true\n  let charCodeToPatternIdxToConfig = []\n\n  if (!options.safeMode) {\n    tracer(\"First Char Optimization\", () => {\n      charCodeToPatternIdxToConfig = reduce(\n        onlyRelevantTypes,\n        (result, currTokType, idx) => {\n          if (typeof currTokType.PATTERN === \"string\") {\n            const charCode = currTokType.PATTERN.charCodeAt(0)\n            const optimizedIdx = charCodeToOptimizedIndex(charCode)\n            addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx])\n          } else if (isArray(currTokType.START_CHARS_HINT)) {\n            let lastOptimizedIdx\n            forEach(currTokType.START_CHARS_HINT, (charOrInt) => {\n              const charCode =\n                typeof charOrInt === \"string\"\n                  ? charOrInt.charCodeAt(0)\n                  : charOrInt\n              const currOptimizedIdx = charCodeToOptimizedIndex(charCode)\n              // Avoid adding the config multiple times\n              /* istanbul ignore else */\n              // - Difficult to check this scenario effects as it is only a performance\n              //   optimization that does not change correctness\n              if (lastOptimizedIdx !== currOptimizedIdx) {\n                lastOptimizedIdx = currOptimizedIdx\n                addToMapOfArrays(\n                  result,\n                  currOptimizedIdx,\n                  patternIdxToConfig[idx]\n                )\n              }\n            })\n          } else if (isRegExp(currTokType.PATTERN)) {\n            if (currTokType.PATTERN.unicode) {\n              canBeOptimized = false\n              if (options.ensureOptimizations) {\n                PRINT_ERROR(\n                  `${failedOptimizationPrefixMsg}` +\n                    `\\tUnable to analyze < ${currTokType.PATTERN.toString()} > pattern.\\n` +\n                    \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" +\n                    \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                    \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\"\n                )\n              }\n            } else {\n              const optimizedCodes = getOptimizedStartCodesIndices(\n                currTokType.PATTERN,\n                options.ensureOptimizations\n              )\n              /* istanbul ignore if */\n              // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n              // the first should be a different validation and the second cannot be tested.\n              if (isEmpty(optimizedCodes)) {\n                // we cannot understand what codes may start possible matches\n                // The optimization correctness requires knowing start codes for ALL patterns.\n                // Not actually sure this is an error, no debug message\n                canBeOptimized = false\n              }\n              forEach(optimizedCodes, (code) => {\n                addToMapOfArrays(result, code, patternIdxToConfig[idx])\n              })\n            }\n          } else {\n            if (options.ensureOptimizations) {\n              PRINT_ERROR(\n                `${failedOptimizationPrefixMsg}` +\n                  `\\tTokenType: <${currTokType.name}> is using a custom token pattern without providing <start_chars_hint> parameter.\\n` +\n                  \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                  \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\"\n              )\n            }\n            canBeOptimized = false\n          }\n\n          return result\n        },\n        []\n      )\n    })\n  }\n  tracer(\"ArrayPacking\", () => {\n    charCodeToPatternIdxToConfig = packArray(charCodeToPatternIdxToConfig)\n  })\n\n  return {\n    emptyGroups: emptyGroups,\n    patternIdxToConfig: patternIdxToConfig,\n    charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n    hasCustom: hasCustom,\n    canBeOptimized: canBeOptimized\n  }\n}\n\nexport function validatePatterns(\n  tokenTypes: TokenType[],\n  validModesNames: string[]\n): ILexerDefinitionError[] {\n  let errors = []\n\n  const missingResult = findMissingPatterns(tokenTypes)\n  errors = errors.concat(missingResult.errors)\n\n  const invalidResult = findInvalidPatterns(missingResult.valid)\n  const validTokenTypes = invalidResult.valid\n  errors = errors.concat(invalidResult.errors)\n\n  errors = errors.concat(validateRegExpPattern(validTokenTypes))\n\n  errors = errors.concat(findInvalidGroupType(validTokenTypes))\n\n  errors = errors.concat(\n    findModesThatDoNotExist(validTokenTypes, validModesNames)\n  )\n\n  errors = errors.concat(findUnreachablePatterns(validTokenTypes))\n\n  return errors\n}\n\nfunction validateRegExpPattern(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  let errors = []\n  const withRegExpPatterns = filter(tokenTypes, (currTokType) =>\n    isRegExp(currTokType[PATTERN])\n  )\n\n  errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns))\n\n  errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns))\n\n  errors = errors.concat(findUnsupportedFlags(withRegExpPatterns))\n\n  errors = errors.concat(findDuplicatePatterns(withRegExpPatterns))\n\n  errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns))\n\n  return errors\n}\n\nexport interface ILexerFilterResult {\n  errors: ILexerDefinitionError[]\n  valid: TokenType[]\n}\n\nexport function findMissingPatterns(\n  tokenTypes: TokenType[]\n): ILexerFilterResult {\n  const tokenTypesWithMissingPattern = filter(tokenTypes, (currType) => {\n    return !has(currType, PATTERN)\n  })\n\n  const errors = map(tokenTypesWithMissingPattern, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- missing static 'PATTERN' property\",\n      type: LexerDefinitionErrorType.MISSING_PATTERN,\n      tokenTypes: [currType]\n    }\n  })\n\n  const valid = difference(tokenTypes, tokenTypesWithMissingPattern)\n  return { errors, valid }\n}\n\nexport function findInvalidPatterns(\n  tokenTypes: TokenType[]\n): ILexerFilterResult {\n  const tokenTypesWithInvalidPattern = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN]\n    return (\n      !isRegExp(pattern) &&\n      !isFunction(pattern) &&\n      !has(pattern, \"exec\") &&\n      !isString(pattern)\n    )\n  })\n\n  const errors = map(tokenTypesWithInvalidPattern, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' can only be a RegExp, a\" +\n        \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n      type: LexerDefinitionErrorType.INVALID_PATTERN,\n      tokenTypes: [currType]\n    }\n  })\n\n  const valid = difference(tokenTypes, tokenTypesWithInvalidPattern)\n  return { errors, valid }\n}\n\nconst end_of_input = /[^\\\\][\\$]/\n\nexport function findEndOfInputAnchor(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  class EndAnchorFinder extends BaseRegExpVisitor {\n    found = false\n\n    visitEndAnchor(node) {\n      this.found = true\n    }\n  }\n\n  const invalidRegex = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN]\n\n    try {\n      const regexpAst = getRegExpAst(pattern)\n      const endAnchorVisitor = new EndAnchorFinder()\n      endAnchorVisitor.visit(regexpAst)\n\n      return endAnchorVisitor.found\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return end_of_input.test(pattern.source)\n    }\n  })\n\n  const errors = map(invalidRegex, (currType) => {\n    return {\n      message:\n        \"Unexpected RegExp Anchor Error:\\n\" +\n        \"\\tToken Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" +\n        \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    }\n  })\n\n  return errors\n}\n\nexport function findEmptyMatchRegExps(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  const matchesEmptyString = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN]\n    return pattern.test(\"\")\n  })\n\n  const errors = map(matchesEmptyString, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' must not match an empty string\",\n      type: LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n      tokenTypes: [currType]\n    }\n  })\n\n  return errors\n}\n\nconst start_of_input = /[^\\\\[][\\^]|^\\^/\n\nexport function findStartOfInputAnchor(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  class StartAnchorFinder extends BaseRegExpVisitor {\n    found = false\n\n    visitStartAnchor(node) {\n      this.found = true\n    }\n  }\n\n  const invalidRegex = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN]\n    try {\n      const regexpAst = getRegExpAst(pattern)\n      const startAnchorVisitor = new StartAnchorFinder()\n      startAnchorVisitor.visit(regexpAst)\n\n      return startAnchorVisitor.found\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return start_of_input.test(pattern.source)\n    }\n  })\n\n  const errors = map(invalidRegex, (currType) => {\n    return {\n      message:\n        \"Unexpected RegExp Anchor Error:\\n\" +\n        \"\\tToken Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" +\n        \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    }\n  })\n\n  return errors\n}\n\nexport function findUnsupportedFlags(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  const invalidFlags = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN]\n    return pattern instanceof RegExp && (pattern.multiline || pattern.global)\n  })\n\n  const errors = map(invalidFlags, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n      type: LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n      tokenTypes: [currType]\n    }\n  })\n\n  return errors\n}\n\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nexport function findDuplicatePatterns(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  const found = []\n  let identicalPatterns = map(tokenTypes, (outerType: any) => {\n    return reduce(\n      tokenTypes,\n      (result, innerType: any) => {\n        if (\n          outerType.PATTERN.source === innerType.PATTERN.source &&\n          !contains(found, innerType) &&\n          innerType.PATTERN !== Lexer.NA\n        ) {\n          // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n          // in essence we are creating Equivalence classes on equality relation.\n          found.push(innerType)\n          result.push(innerType)\n          return result\n        }\n        return result\n      },\n      []\n    )\n  })\n\n  identicalPatterns = compact(identicalPatterns)\n\n  const duplicatePatterns = filter(identicalPatterns, (currIdenticalSet) => {\n    return currIdenticalSet.length > 1\n  })\n\n  const errors = map(duplicatePatterns, (setOfIdentical: any) => {\n    const tokenTypeNames = map(setOfIdentical, (currType: any) => {\n      return currType.name\n    })\n\n    const dupPatternSrc = (<any>first(setOfIdentical)).PATTERN\n    return {\n      message:\n        `The same RegExp pattern ->${dupPatternSrc}<-` +\n        `has been used in all of the following Token Types: ${tokenTypeNames.join(\n          \", \"\n        )} <-`,\n      type: LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n      tokenTypes: setOfIdentical\n    }\n  })\n\n  return errors\n}\n\nexport function findInvalidGroupType(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  const invalidTypes = filter(tokenTypes, (clazz: any) => {\n    if (!has(clazz, \"GROUP\")) {\n      return false\n    }\n    const group = clazz.GROUP\n\n    return group !== Lexer.SKIPPED && group !== Lexer.NA && !isString(group)\n  })\n\n  const errors = map(invalidTypes, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n      type: LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n      tokenTypes: [currType]\n    }\n  })\n\n  return errors\n}\n\nexport function findModesThatDoNotExist(\n  tokenTypes: TokenType[],\n  validModes: string[]\n): ILexerDefinitionError[] {\n  const invalidModes = filter(tokenTypes, (clazz: any) => {\n    return (\n      clazz.PUSH_MODE !== undefined && !contains(validModes, clazz.PUSH_MODE)\n    )\n  })\n\n  const errors = map(invalidModes, (tokType) => {\n    const msg =\n      `Token Type: ->${tokType.name}<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->${tokType.PUSH_MODE}<-` +\n      `which does not exist`\n    return {\n      message: msg,\n      type: LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n      tokenTypes: [tokType]\n    }\n  })\n\n  return errors\n}\n\nexport function findUnreachablePatterns(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  const errors = []\n\n  const canBeTested = reduce(\n    tokenTypes,\n    (result, tokType, idx) => {\n      const pattern = tokType.PATTERN\n\n      if (pattern === Lexer.NA) {\n        return result\n      }\n\n      // a more comprehensive validation for all forms of regExps would require\n      // deeper regExp analysis capabilities\n      if (isString(pattern)) {\n        result.push({ str: pattern, idx, tokenType: tokType })\n      } else if (isRegExp(pattern) && noMetaChar(pattern)) {\n        result.push({ str: pattern.source, idx, tokenType: tokType })\n      }\n      return result\n    },\n    []\n  )\n\n  forEach(tokenTypes, (tokType, testIdx) => {\n    forEach(canBeTested, ({ str, idx, tokenType }) => {\n      if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n        const msg =\n          `Token: ->${tokenType.name}<- can never be matched.\\n` +\n          `Because it appears AFTER the Token Type ->${tokType.name}<-` +\n          `in the lexer's definition.\\n` +\n          `See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE`\n        errors.push({\n          message: msg,\n          type: LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n          tokenTypes: [tokType, tokenType]\n        })\n      }\n    })\n  })\n\n  return errors\n}\n\nfunction testTokenType(str: string, pattern: any): boolean {\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    const regExpArray = pattern.exec(str)\n    return regExpArray !== null && regExpArray.index === 0\n  } else if (isFunction(pattern)) {\n    // maintain the API of custom patterns\n    return pattern(str, 0, [], {})\n  } else if (has(pattern, \"exec\")) {\n    // maintain the API of custom patterns\n    return pattern.exec(str, 0, [], {})\n  } else if (typeof pattern === \"string\") {\n    return pattern === str\n  } else {\n    throw Error(\"non exhaustive match\")\n  }\n}\n\nfunction noMetaChar(regExp: RegExp): boolean {\n  //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n  const metaChars = [\n    \".\",\n    \"\\\\\",\n    \"[\",\n    \"]\",\n    \"|\",\n    \"^\",\n    \"$\",\n    \"(\",\n    \")\",\n    \"?\",\n    \"*\",\n    \"+\",\n    \"{\"\n  ]\n  return (\n    find(metaChars, (char) => regExp.source.indexOf(char) !== -1) === undefined\n  )\n}\n\nexport function addStartOfInput(pattern: RegExp): RegExp {\n  const flags = pattern.ignoreCase ? \"i\" : \"\"\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(`^(?:${pattern.source})`, flags)\n}\n\nexport function addStickyFlag(pattern: RegExp): RegExp {\n  const flags = pattern.ignoreCase ? \"iy\" : \"y\"\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(`${pattern.source}`, flags)\n}\n\nexport function performRuntimeChecks(\n  lexerDefinition: IMultiModeLexerDefinition,\n  trackLines: boolean,\n  lineTerminatorCharacters: (number | string)[]\n): ILexerDefinitionError[] {\n  const errors = []\n\n  // some run time checks to help the end users.\n  if (!has(lexerDefinition, DEFAULT_MODE)) {\n    errors.push({\n      message:\n        \"A MultiMode Lexer cannot be initialized without a <\" +\n        DEFAULT_MODE +\n        \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n    })\n  }\n  if (!has(lexerDefinition, MODES)) {\n    errors.push({\n      message:\n        \"A MultiMode Lexer cannot be initialized without a <\" +\n        MODES +\n        \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n    })\n  }\n\n  if (\n    has(lexerDefinition, MODES) &&\n    has(lexerDefinition, DEFAULT_MODE) &&\n    !has(lexerDefinition.modes, lexerDefinition.defaultMode)\n  ) {\n    errors.push({\n      message:\n        `A MultiMode Lexer cannot be initialized with a ${DEFAULT_MODE}: <${lexerDefinition.defaultMode}>` +\n        `which does not exist\\n`,\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n    })\n  }\n\n  if (has(lexerDefinition, MODES)) {\n    forEach(lexerDefinition.modes, (currModeValue, currModeName) => {\n      forEach(currModeValue, (currTokType, currIdx) => {\n        if (isUndefined(currTokType)) {\n          errors.push({\n            message:\n              `A Lexer cannot be initialized using an undefined Token Type. Mode:` +\n              `<${currModeName}> at index: <${currIdx}>\\n`,\n            type: LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n          })\n        }\n      })\n    })\n  }\n\n  return errors\n}\n\nexport function performWarningRuntimeChecks(\n  lexerDefinition: IMultiModeLexerDefinition,\n  trackLines: boolean,\n  lineTerminatorCharacters: (number | string)[]\n): ILexerDefinitionError[] {\n  const warnings = []\n  let hasAnyLineBreak = false\n  const allTokenTypes = compact(\n    flatten(mapValues(lexerDefinition.modes, (tokTypes) => tokTypes))\n  )\n\n  const concreteTokenTypes = reject(\n    allTokenTypes,\n    (currType) => currType[PATTERN] === Lexer.NA\n  )\n  const terminatorCharCodes = getCharCodes(lineTerminatorCharacters)\n  if (trackLines) {\n    forEach(concreteTokenTypes, (tokType) => {\n      const currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes)\n      if (currIssue !== false) {\n        const message = buildLineBreakIssueMessage(tokType, currIssue)\n        const warningDescriptor = {\n          message,\n          type: currIssue.issue,\n          tokenType: tokType\n        }\n        warnings.push(warningDescriptor)\n      } else {\n        // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n        if (has(tokType, \"LINE_BREAKS\")) {\n          if (tokType.LINE_BREAKS === true) {\n            hasAnyLineBreak = true\n          }\n        } else {\n          if (canMatchCharCode(terminatorCharCodes, tokType.PATTERN)) {\n            hasAnyLineBreak = true\n          }\n        }\n      }\n    })\n  }\n\n  if (trackLines && !hasAnyLineBreak) {\n    warnings.push({\n      message:\n        \"Warning: No LINE_BREAKS Found.\\n\" +\n        \"\\tThis Lexer has been defined to track line and column information,\\n\" +\n        \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" +\n        \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n    })\n  }\n  return warnings\n}\n\nexport function cloneEmptyGroups(emptyGroups: {\n  [groupName: string]: IToken\n}): { [groupName: string]: IToken } {\n  const clonedResult: any = {}\n  const groupKeys = keys(emptyGroups)\n\n  forEach(groupKeys, (currKey) => {\n    const currGroupValue = emptyGroups[currKey]\n\n    /* istanbul ignore else */\n    if (isArray(currGroupValue)) {\n      clonedResult[currKey] = []\n    } else {\n      throw Error(\"non exhaustive match\")\n    }\n  })\n\n  return clonedResult\n}\n\n// TODO: refactor to avoid duplication\nexport function isCustomPattern(tokenType: any): boolean {\n  const pattern = tokenType.PATTERN\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    return false\n  } else if (isFunction(pattern)) {\n    // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n    return true\n  } else if (has(pattern, \"exec\")) {\n    // ICustomPattern\n    return true\n  } else if (isString(pattern)) {\n    return false\n  } else {\n    throw Error(\"non exhaustive match\")\n  }\n}\n\nexport function isShortPattern(pattern: any): number | boolean {\n  if (isString(pattern) && pattern.length === 1) {\n    return pattern.charCodeAt(0)\n  } else {\n    return false\n  }\n}\n\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexport const LineTerminatorOptimizedTester: ILineTerminatorsTester = {\n  // implements /\\n|\\r\\n?/g.test\n  test: function (text) {\n    const len = text.length\n    for (let i = this.lastIndex; i < len; i++) {\n      const c = text.charCodeAt(i)\n      if (c === 10) {\n        this.lastIndex = i + 1\n        return true\n      } else if (c === 13) {\n        if (text.charCodeAt(i + 1) === 10) {\n          this.lastIndex = i + 2\n        } else {\n          this.lastIndex = i + 1\n        }\n        return true\n      }\n    }\n    return false\n  },\n\n  lastIndex: 0\n}\n\nfunction checkLineBreaksIssues(\n  tokType: TokenType,\n  lineTerminatorCharCodes: number[]\n):\n  | {\n      issue:\n        | LexerDefinitionErrorType.IDENTIFY_TERMINATOR\n        | LexerDefinitionErrorType.CUSTOM_LINE_BREAK\n      errMsg?: string\n    }\n  | false {\n  if (has(tokType, \"LINE_BREAKS\")) {\n    // if the user explicitly declared the line_breaks option we will respect their choice\n    // and assume it is correct.\n    return false\n  } else {\n    /* istanbul ignore else */\n    if (isRegExp(tokType.PATTERN)) {\n      try {\n        // TODO: why is the casting suddenly needed?\n        canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN as RegExp)\n      } catch (e) {\n        /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n        return {\n          issue: LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n          errMsg: e.message\n        }\n      }\n      return false\n    } else if (isString(tokType.PATTERN)) {\n      // string literal patterns can always be analyzed to detect line terminator usage\n      return false\n    } else if (isCustomPattern(tokType)) {\n      // custom token types\n      return { issue: LexerDefinitionErrorType.CUSTOM_LINE_BREAK }\n    } else {\n      throw Error(\"non exhaustive match\")\n    }\n  }\n}\n\nexport function buildLineBreakIssueMessage(\n  tokType: TokenType,\n  details: {\n    issue:\n      | LexerDefinitionErrorType.IDENTIFY_TERMINATOR\n      | LexerDefinitionErrorType.CUSTOM_LINE_BREAK\n    errMsg?: string\n  }\n): string {\n  /* istanbul ignore else */\n  if (details.issue === LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n    return (\n      \"Warning: unable to identify line terminator usage in pattern.\\n\" +\n      `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n      `\\t Root cause: ${details.errMsg}.\\n` +\n      \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\"\n    )\n  } else if (details.issue === LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n    return (\n      \"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" +\n      `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n      \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\"\n    )\n  } else {\n    throw Error(\"non exhaustive match\")\n  }\n}\n\nfunction getCharCodes(charsOrCodes: (number | string)[]): number[] {\n  const charCodes = map(charsOrCodes, (numOrString) => {\n    if (isString(numOrString) && numOrString.length > 0) {\n      return numOrString.charCodeAt(0)\n    } else {\n      return numOrString\n    }\n  })\n\n  return charCodes\n}\n\nfunction addToMapOfArrays(map, key, value): void {\n  if (map[key] === undefined) {\n    map[key] = [value]\n  } else {\n    map[key].push(value)\n  }\n}\n\nexport const minOptimizationVal = 256\n\n/**\n * We ae mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nlet charCodeToOptimizedIdxMap = []\nexport function charCodeToOptimizedIndex(charCode) {\n  return charCode < minOptimizationVal\n    ? charCode\n    : charCodeToOptimizedIdxMap[charCode]\n}\n\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nfunction initCharCodeToOptimizedIndexMap() {\n  if (isEmpty(charCodeToOptimizedIdxMap)) {\n    charCodeToOptimizedIdxMap = new Array(65536)\n    for (let i = 0; i < 65536; i++) {\n      /* tslint:disable */\n      charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i\n      /* tslint:enable */\n    }\n  }\n}\n"]},"metadata":{},"sourceType":"script"}