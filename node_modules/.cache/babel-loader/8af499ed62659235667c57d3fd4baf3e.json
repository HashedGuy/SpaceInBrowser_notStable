{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.LexerAdapter = void 0;\n\nvar parser_1 = require(\"../parser\");\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\n\n\nvar LexerAdapter =\n/** @class */\nfunction () {\n  function LexerAdapter() {}\n\n  LexerAdapter.prototype.initLexerAdapter = function () {\n    this.tokVector = [];\n    this.tokVectorLength = 0;\n    this.currIdx = -1;\n  };\n\n  Object.defineProperty(LexerAdapter.prototype, \"input\", {\n    get: function get() {\n      return this.tokVector;\n    },\n    set: function set(newInput) {\n      // @ts-ignore - `this parameter` not supported in setters/getters\n      //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n      if (this.selfAnalysisDone !== true) {\n        throw Error(\"Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.\");\n      } // @ts-ignore - `this parameter` not supported in setters/getters\n      //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n\n\n      this.reset();\n      this.tokVector = newInput;\n      this.tokVectorLength = newInput.length;\n    },\n    enumerable: false,\n    configurable: true\n  }); // skips a token and returns the next token\n\n  LexerAdapter.prototype.SKIP_TOKEN = function () {\n    if (this.currIdx <= this.tokVector.length - 2) {\n      this.consumeToken();\n      return this.LA(1);\n    } else {\n      return parser_1.END_OF_FILE;\n    }\n  }; // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n  // or lexers dependent on parser context.\n\n\n  LexerAdapter.prototype.LA = function (howMuch) {\n    var soughtIdx = this.currIdx + howMuch;\n\n    if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n      return parser_1.END_OF_FILE;\n    } else {\n      return this.tokVector[soughtIdx];\n    }\n  };\n\n  LexerAdapter.prototype.consumeToken = function () {\n    this.currIdx++;\n  };\n\n  LexerAdapter.prototype.exportLexerState = function () {\n    return this.currIdx;\n  };\n\n  LexerAdapter.prototype.importLexerState = function (newState) {\n    this.currIdx = newState;\n  };\n\n  LexerAdapter.prototype.resetLexerState = function () {\n    this.currIdx = -1;\n  };\n\n  LexerAdapter.prototype.moveToTerminatedState = function () {\n    this.currIdx = this.tokVector.length - 1;\n  };\n\n  LexerAdapter.prototype.getLexerPosition = function () {\n    return this.exportLexerState();\n  };\n\n  return LexerAdapter;\n}();\n\nexports.LexerAdapter = LexerAdapter;","map":{"version":3,"mappings":";;;;;;;AAAA;AAIA;;;;;;;;;AAOA;AAAA;AAAA;AAAA,2BA0EC;;AArECA;AACE,SAAKC,SAAL,GAAiB,EAAjB;AACA,SAAKC,eAAL,GAAuB,CAAvB;AACA,SAAKC,OAAL,GAAe,CAAC,CAAhB;AACD,GAJD;;AAMAC,wBAAIJ,sBAAJ,EAAI,OAAJ,EAAS;SAeT;AACE,aAAO,KAAKC,SAAZ;AACD,KAjBQ;SAAT,aAAUI,QAAV,EAA4B;AAC1B;AACA;AACA,UAAI,KAAKC,gBAAL,KAA0B,IAA9B,EAAoC;AAClC,cAAMC,KAAK,CACT,kFADS,CAAX;AAGD,OAPyB,CAQ1B;AACA;;;AACA,WAAKC,KAAL;AACA,WAAKP,SAAL,GAAiBI,QAAjB;AACA,WAAKH,eAAL,GAAuBG,QAAQ,CAACI,MAAhC;AACD,KAbQ;qBAAA;;AAAA,GAAT,EAXF,CA8BE;;AACAT;AACE,QAAI,KAAKG,OAAL,IAAgB,KAAKF,SAAL,CAAeQ,MAAf,GAAwB,CAA5C,EAA+C;AAC7C,WAAKC,YAAL;AACA,aAAO,KAAKC,EAAL,CAAQ,CAAR,CAAP;AACD,KAHD,MAGO;AACL,aAAOC,oBAAP;AACD;AACF,GAPD,CA/BF,CAwCE;AACA;;;AACAZ,wCAAwBa,OAAxB,EAAuC;AACrC,QAAMC,SAAS,GAAG,KAAKX,OAAL,GAAeU,OAAjC;;AACA,QAAIC,SAAS,GAAG,CAAZ,IAAiB,KAAKZ,eAAL,IAAwBY,SAA7C,EAAwD;AACtD,aAAOF,oBAAP;AACD,KAFD,MAEO;AACL,aAAO,KAAKX,SAAL,CAAea,SAAf,CAAP;AACD;AACF,GAPD;;AASAd;AACE,SAAKG,OAAL;AACD,GAFD;;AAIAH;AACE,WAAO,KAAKG,OAAZ;AACD,GAFD;;AAIAH,sDAAsCe,QAAtC,EAAsD;AACpD,SAAKZ,OAAL,GAAeY,QAAf;AACD,GAFD;;AAIAf;AACE,SAAKG,OAAL,GAAe,CAAC,CAAhB;AACD,GAFD;;AAIAH;AACE,SAAKG,OAAL,GAAe,KAAKF,SAAL,CAAeQ,MAAf,GAAwB,CAAvC;AACD,GAFD;;AAIAT;AACE,WAAO,KAAKgB,gBAAL,EAAP;AACD,GAFD;;AAGF;AAAC,CA1ED;;AAAaC","names":["LexerAdapter","tokVector","tokVectorLength","currIdx","Object","newInput","selfAnalysisDone","Error","reset","length","consumeToken","LA","parser_1","howMuch","soughtIdx","newState","exportLexerState","exports"],"sources":["/Users/arbus/Documents/SpaceInBrowser/node_modules/chevrotain/src/parse/parser/traits/lexer_adapter.ts"],"sourcesContent":["import { END_OF_FILE } from \"../parser\"\nimport { IToken } from \"@chevrotain/types\"\nimport { MixedInParser } from \"./parser_traits\"\n\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\nexport class LexerAdapter {\n  tokVector: IToken[]\n  tokVectorLength\n  currIdx: number\n\n  initLexerAdapter() {\n    this.tokVector = []\n    this.tokVectorLength = 0\n    this.currIdx = -1\n  }\n\n  set input(newInput: IToken[]) {\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    if (this.selfAnalysisDone !== true) {\n      throw Error(\n        `Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.`\n      )\n    }\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    this.reset()\n    this.tokVector = newInput\n    this.tokVectorLength = newInput.length\n  }\n\n  get input(): IToken[] {\n    return this.tokVector\n  }\n\n  // skips a token and returns the next token\n  SKIP_TOKEN(this: MixedInParser): IToken {\n    if (this.currIdx <= this.tokVector.length - 2) {\n      this.consumeToken()\n      return this.LA(1)\n    } else {\n      return END_OF_FILE\n    }\n  }\n\n  // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n  // or lexers dependent on parser context.\n  LA(this: MixedInParser, howMuch: number): IToken {\n    const soughtIdx = this.currIdx + howMuch\n    if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n      return END_OF_FILE\n    } else {\n      return this.tokVector[soughtIdx]\n    }\n  }\n\n  consumeToken(this: MixedInParser) {\n    this.currIdx++\n  }\n\n  exportLexerState(this: MixedInParser): number {\n    return this.currIdx\n  }\n\n  importLexerState(this: MixedInParser, newState: number) {\n    this.currIdx = newState\n  }\n\n  resetLexerState(this: MixedInParser): void {\n    this.currIdx = -1\n  }\n\n  moveToTerminatedState(this: MixedInParser): void {\n    this.currIdx = this.tokVector.length - 1\n  }\n\n  getLexerPosition(this: MixedInParser): number {\n    return this.exportLexerState()\n  }\n}\n"]},"metadata":{},"sourceType":"script"}