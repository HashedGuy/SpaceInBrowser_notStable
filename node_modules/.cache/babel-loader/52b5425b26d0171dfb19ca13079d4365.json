{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.attemptInRepetitionRecovery = exports.Recoverable = exports.InRuleRecoveryException = exports.IN_RULE_RECOVERY_EXCEPTION = exports.EOF_FOLLOW_KEY = void 0;\n\nvar tokens_public_1 = require(\"../../../scan/tokens_public\");\n\nvar utils_1 = require(\"@chevrotain/utils\");\n\nvar exceptions_public_1 = require(\"../../exceptions_public\");\n\nvar constants_1 = require(\"../../constants\");\n\nvar parser_1 = require(\"../parser\");\n\nexports.EOF_FOLLOW_KEY = {};\nexports.IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\n\nfunction InRuleRecoveryException(message) {\n  this.name = exports.IN_RULE_RECOVERY_EXCEPTION;\n  this.message = message;\n}\n\nexports.InRuleRecoveryException = InRuleRecoveryException;\nInRuleRecoveryException.prototype = Error.prototype;\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\n\nvar Recoverable =\n/** @class */\nfunction () {\n  function Recoverable() {}\n\n  Recoverable.prototype.initRecoverable = function (config) {\n    this.firstAfterRepMap = {};\n    this.resyncFollows = {};\n    this.recoveryEnabled = (0, utils_1.has)(config, \"recoveryEnabled\") ? config.recoveryEnabled : parser_1.DEFAULT_PARSER_CONFIG.recoveryEnabled; // performance optimization, NOOP will be inlined which\n    // effectively means that this optional feature does not exist\n    // when not used.\n\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery;\n    }\n  };\n\n  Recoverable.prototype.getTokenToInsert = function (tokType) {\n    var tokToInsert = (0, tokens_public_1.createTokenInstance)(tokType, \"\", NaN, NaN, NaN, NaN, NaN, NaN);\n    tokToInsert.isInsertedInRecovery = true;\n    return tokToInsert;\n  };\n\n  Recoverable.prototype.canTokenTypeBeInsertedInRecovery = function (tokType) {\n    return true;\n  };\n\n  Recoverable.prototype.tryInRepetitionRecovery = function (grammarRule, grammarRuleArgs, lookAheadFunc, expectedTokType) {\n    var _this = this; // TODO: can the resyncTokenType be cached?\n\n\n    var reSyncTokType = this.findReSyncTokenType();\n    var savedLexerState = this.exportLexerState();\n    var resyncedTokens = [];\n    var passedResyncPoint = false;\n    var nextTokenWithoutResync = this.LA(1);\n    var currToken = this.LA(1);\n\n    var generateErrorMessage = function generateErrorMessage() {\n      var previousToken = _this.LA(0); // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n      // the error that would have been thrown\n\n\n      var msg = _this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: _this.getCurrRuleFullName()\n      });\n\n      var error = new exceptions_public_1.MismatchedTokenException(msg, nextTokenWithoutResync, _this.LA(0)); // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n\n      error.resyncedTokens = (0, utils_1.dropRight)(resyncedTokens);\n\n      _this.SAVE_ERROR(error);\n    };\n\n    while (!passedResyncPoint) {\n      // re-synced to a point where we can safely exit the repetition/\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage();\n        return; // must return here to avoid reverting the inputIdx\n      } else if (lookAheadFunc.call(this)) {\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n        generateErrorMessage(); // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n\n        grammarRule.apply(this, grammarRuleArgs);\n        return; // must return here to avoid reverting the inputIdx\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true;\n      } else {\n        currToken = this.SKIP_TOKEN();\n        this.addToResyncTokens(currToken, resyncedTokens);\n      }\n    } // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n    // \"between rules\" resync recovery later in the flow.\n\n\n    this.importLexerState(savedLexerState);\n  };\n\n  Recoverable.prototype.shouldInRepetitionRecoveryBeTried = function (expectTokAfterLastMatch, nextTokIdx, notStuck) {\n    // Edge case of arriving from a MANY repetition which is stuck\n    // Attempting recovery in this case could cause an infinite loop\n    if (notStuck === false) {\n      return false;\n    } // arguments to try and perform resync into the next iteration of the many are missing\n\n\n    if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n      return false;\n    } // no need to recover, next token is what we expect...\n\n\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false;\n    } // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n    // and prefer some backtracking path that includes recovered errors.\n\n\n    if (this.isBackTracking()) {\n      return false;\n    } // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n    //noinspection RedundantIfStatementJS\n\n\n    if (this.canPerformInRuleRecovery(expectTokAfterLastMatch, this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx))) {\n      return false;\n    }\n\n    return true;\n  }; // Error Recovery functionality\n\n\n  Recoverable.prototype.getFollowsForInRuleRecovery = function (tokType, tokIdxInRule) {\n    var grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule);\n    var follows = this.getNextPossibleTokenTypes(grammarPath);\n    return follows;\n  };\n\n  Recoverable.prototype.tryInRuleRecovery = function (expectedTokType, follows) {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      var tokToInsert = this.getTokenToInsert(expectedTokType);\n      return tokToInsert;\n    }\n\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      var nextTok = this.SKIP_TOKEN();\n      this.consumeToken();\n      return nextTok;\n    }\n\n    throw new InRuleRecoveryException(\"sad sad panda\");\n  };\n\n  Recoverable.prototype.canPerformInRuleRecovery = function (expectedToken, follows) {\n    return this.canRecoverWithSingleTokenInsertion(expectedToken, follows) || this.canRecoverWithSingleTokenDeletion(expectedToken);\n  };\n\n  Recoverable.prototype.canRecoverWithSingleTokenInsertion = function (expectedTokType, follows) {\n    var _this = this;\n\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false;\n    } // must know the possible following tokens to perform single token insertion\n\n\n    if ((0, utils_1.isEmpty)(follows)) {\n      return false;\n    }\n\n    var mismatchedTok = this.LA(1);\n    var isMisMatchedTokInFollows = (0, utils_1.find)(follows, function (possibleFollowsTokType) {\n      return _this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n    }) !== undefined;\n    return isMisMatchedTokInFollows;\n  };\n\n  Recoverable.prototype.canRecoverWithSingleTokenDeletion = function (expectedTokType) {\n    var isNextTokenWhatIsExpected = this.tokenMatcher(this.LA(2), expectedTokType);\n    return isNextTokenWhatIsExpected;\n  };\n\n  Recoverable.prototype.isInCurrentRuleReSyncSet = function (tokenTypeIdx) {\n    var followKey = this.getCurrFollowKey();\n    var currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n    return (0, utils_1.contains)(currentRuleReSyncSet, tokenTypeIdx);\n  };\n\n  Recoverable.prototype.findReSyncTokenType = function () {\n    var allPossibleReSyncTokTypes = this.flattenFollowSet(); // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n\n    var nextToken = this.LA(1);\n    var k = 2;\n\n    while (true) {\n      var nextTokenType = nextToken.tokenType;\n\n      if ((0, utils_1.contains)(allPossibleReSyncTokTypes, nextTokenType)) {\n        return nextTokenType;\n      }\n\n      nextToken = this.LA(k);\n      k++;\n    }\n  };\n\n  Recoverable.prototype.getCurrFollowKey = function () {\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n    if (this.RULE_STACK.length === 1) {\n      return exports.EOF_FOLLOW_KEY;\n    }\n\n    var currRuleShortName = this.getLastExplicitRuleShortName();\n    var currRuleIdx = this.getLastExplicitRuleOccurrenceIndex();\n    var prevRuleShortName = this.getPreviousExplicitRuleShortName();\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName)\n    };\n  };\n\n  Recoverable.prototype.buildFullFollowKeyStack = function () {\n    var _this = this;\n\n    var explicitRuleStack = this.RULE_STACK;\n    var explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK;\n    return (0, utils_1.map)(explicitRuleStack, function (ruleName, idx) {\n      if (idx === 0) {\n        return exports.EOF_FOLLOW_KEY;\n      }\n\n      return {\n        ruleName: _this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: _this.shortRuleNameToFullName(explicitRuleStack[idx - 1])\n      };\n    });\n  };\n\n  Recoverable.prototype.flattenFollowSet = function () {\n    var _this = this;\n\n    var followStack = (0, utils_1.map)(this.buildFullFollowKeyStack(), function (currKey) {\n      return _this.getFollowSetFromFollowKey(currKey);\n    });\n    return (0, utils_1.flatten)(followStack);\n  };\n\n  Recoverable.prototype.getFollowSetFromFollowKey = function (followKey) {\n    if (followKey === exports.EOF_FOLLOW_KEY) {\n      return [tokens_public_1.EOF];\n    }\n\n    var followName = followKey.ruleName + followKey.idxInCallingRule + constants_1.IN + followKey.inRule;\n    return this.resyncFollows[followName];\n  }; // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n\n\n  Recoverable.prototype.addToResyncTokens = function (token, resyncTokens) {\n    if (!this.tokenMatcher(token, tokens_public_1.EOF)) {\n      resyncTokens.push(token);\n    }\n\n    return resyncTokens;\n  };\n\n  Recoverable.prototype.reSyncTo = function (tokType) {\n    var resyncedTokens = [];\n    var nextTok = this.LA(1);\n\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN();\n      this.addToResyncTokens(nextTok, resyncedTokens);\n    } // the last token is not part of the error.\n\n\n    return (0, utils_1.dropRight)(resyncedTokens);\n  };\n\n  Recoverable.prototype.attemptInRepetitionRecovery = function (prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {// by default this is a NO-OP\n    // The actual implementation is with the function(not method) below\n  };\n\n  Recoverable.prototype.getCurrentGrammarPath = function (tokType, tokIdxInRule) {\n    var pathRuleStack = this.getHumanReadableRuleStack();\n    var pathOccurrenceStack = (0, utils_1.cloneArr)(this.RULE_OCCURRENCE_STACK);\n    var grammarPath = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule\n    };\n    return grammarPath;\n  };\n\n  Recoverable.prototype.getHumanReadableRuleStack = function () {\n    var _this = this;\n\n    return (0, utils_1.map)(this.RULE_STACK, function (currShortName) {\n      return _this.shortRuleNameToFullName(currShortName);\n    });\n  };\n\n  return Recoverable;\n}();\n\nexports.Recoverable = Recoverable;\n\nfunction attemptInRepetitionRecovery(prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n  var key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n  var firstAfterRepInfo = this.firstAfterRepMap[key];\n\n  if (firstAfterRepInfo === undefined) {\n    var currRuleName = this.getCurrRuleFullName();\n    var ruleGrammar = this.getGAstProductions()[currRuleName];\n    var walker = new nextToksWalker(ruleGrammar, prodOccurrence);\n    firstAfterRepInfo = walker.startWalking();\n    this.firstAfterRepMap[key] = firstAfterRepInfo;\n  }\n\n  var expectTokAfterLastMatch = firstAfterRepInfo.token;\n  var nextTokIdx = firstAfterRepInfo.occurrence;\n  var isEndOfRule = firstAfterRepInfo.isEndOfRule; // special edge case of a TOP most repetition after which the input should END.\n  // this will force an attempt for inRule recovery in that scenario.\n\n  if (this.RULE_STACK.length === 1 && isEndOfRule && expectTokAfterLastMatch === undefined) {\n    expectTokAfterLastMatch = tokens_public_1.EOF;\n    nextTokIdx = 1;\n  }\n\n  if (this.shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx, notStuck)) {\n    // TODO: performance optimization: instead of passing the original args here, we modify\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n    // to avoid searching the cache for it once more.\n    this.tryInRepetitionRecovery(prodFunc, args, lookaheadFunc, expectTokAfterLastMatch);\n  }\n}\n\nexports.attemptInRepetitionRecovery = attemptInRepetitionRecovery;","map":{"version":3,"mappings":";;;;;;;AAAA;;AAKA;;AAgBA;;AACA;;AAEA;;AAEaA,yBAAsB,EAAtB;AAQAA,qCAA6B,yBAA7B;;AAEb,SAAgBC,uBAAhB,CAAwCC,OAAxC,EAAuD;AACrD,OAAKC,IAAL,GAAYH,kCAAZ;AACA,OAAKE,OAAL,GAAeA,OAAf;AACD;;AAHDF;AAKAC,uBAAuB,CAACG,SAAxB,GAAoCC,KAAK,CAACD,SAA1C;AAEA;;;;AAGA;AAAA;AAAA;AAAA,0BAmWC;;AA9VCE,oDAAgBC,MAAhB,EAAqC;AACnC,SAAKC,gBAAL,GAAwB,EAAxB;AACA,SAAKC,aAAL,GAAqB,EAArB;AAEA,SAAKC,eAAL,GAAuB,iBAAIH,MAAJ,EAAY,iBAAZ,IACnBA,MAAM,CAACG,eADY,GAEnBC,+BAAsBD,eAF1B,CAJmC,CAQnC;AACA;AACA;;AACA,QAAI,KAAKA,eAAT,EAA0B;AACxB,WAAKE,2BAAL,GAAmCA,2BAAnC;AACD;AACF,GAdD;;AAgBON,2CAAP,UAAwBO,OAAxB,EAA0C;AACxC,QAAMC,WAAW,GAAG,yCAClBD,OADkB,EAElB,EAFkB,EAGlBE,GAHkB,EAIlBA,GAJkB,EAKlBA,GALkB,EAMlBA,GANkB,EAOlBA,GAPkB,EAQlBA,GARkB,CAApB;AAUAD,eAAW,CAACE,oBAAZ,GAAmC,IAAnC;AACA,WAAOF,WAAP;AACD,GAbM;;AAeAR,2DAAP,UAAwCO,OAAxC,EAA0D;AACxD,WAAO,IAAP;AACD,GAFM;;AAIPP,4DAEEW,WAFF,EAGEC,eAHF,EAIEC,aAJF,EAKEC,eALF,EAK4B;AAL5B,qBAK4B,CAE1B;;;AACA,QAAMC,aAAa,GAAG,KAAKC,mBAAL,EAAtB;AACA,QAAMC,eAAe,GAAG,KAAKC,gBAAL,EAAxB;AACA,QAAMC,cAAc,GAAG,EAAvB;AACA,QAAIC,iBAAiB,GAAG,KAAxB;AAEA,QAAMC,sBAAsB,GAAG,KAAKC,EAAL,CAAQ,CAAR,CAA/B;AACA,QAAIC,SAAS,GAAG,KAAKD,EAAL,CAAQ,CAAR,CAAhB;;AAEA,QAAME,oBAAoB,GAAG,SAAvBA,oBAAuB;AAC3B,UAAMC,aAAa,GAAGC,KAAI,CAACJ,EAAL,CAAQ,CAAR,CAAtB,CAD2B,CAE3B;AACA;;;AACA,UAAMK,GAAG,GAAGD,KAAI,CAACE,oBAAL,CAA0BC,yBAA1B,CAAoD;AAC9DC,gBAAQ,EAAEhB,eADoD;AAE9DiB,cAAM,EAAEV,sBAFsD;AAG9DW,gBAAQ,EAAEP,aAHoD;AAI9DQ,gBAAQ,EAAEP,KAAI,CAACQ,mBAAL;AAJoD,OAApD,CAAZ;;AAMA,UAAMC,KAAK,GAAG,IAAIC,4CAAJ,CACZT,GADY,EAEZN,sBAFY,EAGZK,KAAI,CAACJ,EAAL,CAAQ,CAAR,CAHY,CAAd,CAV2B,CAe3B;;AACAa,WAAK,CAAChB,cAAN,GAAuB,uBAAUA,cAAV,CAAvB;;AACAO,WAAI,CAACW,UAAL,CAAgBF,KAAhB;AACD,KAlBD;;AAoBA,WAAO,CAACf,iBAAR,EAA2B;AACzB;AACA,UAAI,KAAKkB,YAAL,CAAkBf,SAAlB,EAA6BT,eAA7B,CAAJ,EAAmD;AACjDU,4BAAoB;AACpB,eAFiD,CAE1C;AACR,OAHD,MAGO,IAAIX,aAAa,CAAC0B,IAAd,CAAmB,IAAnB,CAAJ,EAA8B;AACnC;AACAf,4BAAoB,GAFe,CAGnC;;AACAb,mBAAW,CAAC6B,KAAZ,CAAkB,IAAlB,EAAwB5B,eAAxB;AACA,eALmC,CAK5B;AACR,OANM,MAMA,IAAI,KAAK0B,YAAL,CAAkBf,SAAlB,EAA6BR,aAA7B,CAAJ,EAAiD;AACtDK,yBAAiB,GAAG,IAApB;AACD,OAFM,MAEA;AACLG,iBAAS,GAAG,KAAKkB,UAAL,EAAZ;AACA,aAAKC,iBAAL,CAAuBnB,SAAvB,EAAkCJ,cAAlC;AACD;AACF,KAhDyB,CAkD1B;AACA;AACA;;;AACA,SAAKwB,gBAAL,CAAsB1B,eAAtB;AACD,GA3DD;;AA6DAjB,sEAEE4C,uBAFF,EAGEC,UAHF,EAIEC,QAJF,EAI+B;AAE7B;AACA;AACA,QAAIA,QAAQ,KAAK,KAAjB,EAAwB;AACtB,aAAO,KAAP;AACD,KAN4B,CAQ7B;;;AACA,QAAIF,uBAAuB,KAAKG,SAA5B,IAAyCF,UAAU,KAAKE,SAA5D,EAAuE;AACrE,aAAO,KAAP;AACD,KAX4B,CAa7B;;;AACA,QAAI,KAAKT,YAAL,CAAkB,KAAKhB,EAAL,CAAQ,CAAR,CAAlB,EAA8BsB,uBAA9B,CAAJ,EAA4D;AAC1D,aAAO,KAAP;AACD,KAhB4B,CAkB7B;AACA;;;AACA,QAAI,KAAKI,cAAL,EAAJ,EAA2B;AACzB,aAAO,KAAP;AACD,KAtB4B,CAwB7B;AACA;AACA;;;AACA,QACE,KAAKC,wBAAL,CACEL,uBADF,EAEE,KAAKM,2BAAL,CAAiCN,uBAAjC,EAA0DC,UAA1D,CAFF,CADF,EAKE;AACA,aAAO,KAAP;AACD;;AAED,WAAO,IAAP;AACD,GAzCD,CArGF,CAgJE;;;AACA7C,gEAEEO,OAFF,EAGE4C,YAHF,EAGsB;AAEpB,QAAMC,WAAW,GAAG,KAAKC,qBAAL,CAA2B9C,OAA3B,EAAoC4C,YAApC,CAApB;AACA,QAAMG,OAAO,GAAG,KAAKC,yBAAL,CAA+BH,WAA/B,CAAhB;AACA,WAAOE,OAAP;AACD,GARD;;AAUAtD,sDAEEc,eAFF,EAGEwC,OAHF,EAGsB;AAEpB,QAAI,KAAKE,kCAAL,CAAwC1C,eAAxC,EAAyDwC,OAAzD,CAAJ,EAAuE;AACrE,UAAM9C,WAAW,GAAG,KAAKiD,gBAAL,CAAsB3C,eAAtB,CAApB;AACA,aAAON,WAAP;AACD;;AAED,QAAI,KAAKkD,iCAAL,CAAuC5C,eAAvC,CAAJ,EAA6D;AAC3D,UAAM6C,OAAO,GAAG,KAAKlB,UAAL,EAAhB;AACA,WAAKmB,YAAL;AACA,aAAOD,OAAP;AACD;;AAED,UAAM,IAAIhE,uBAAJ,CAA4B,eAA5B,CAAN;AACD,GAjBD;;AAmBAK,6DAEE6D,aAFF,EAGEP,OAHF,EAGsB;AAEpB,WACE,KAAKE,kCAAL,CAAwCK,aAAxC,EAAuDP,OAAvD,KACA,KAAKI,iCAAL,CAAuCG,aAAvC,CAFF;AAID,GATD;;AAWA7D,uEAEEc,eAFF,EAGEwC,OAHF,EAGsB;AAHtB;;AAKE,QAAI,CAAC,KAAKQ,gCAAL,CAAsChD,eAAtC,CAAL,EAA6D;AAC3D,aAAO,KAAP;AACD,KAJmB,CAMpB;;;AACA,QAAI,qBAAQwC,OAAR,CAAJ,EAAsB;AACpB,aAAO,KAAP;AACD;;AAED,QAAMS,aAAa,GAAG,KAAKzC,EAAL,CAAQ,CAAR,CAAtB;AACA,QAAM0C,wBAAwB,GAC5B,kBAAKV,OAAL,EAAc,UAACW,sBAAD,EAAkC;AAC9C,aAAOvC,KAAI,CAACY,YAAL,CAAkByB,aAAlB,EAAiCE,sBAAjC,CAAP;AACD,KAFD,MAEOlB,SAHT;AAKA,WAAOiB,wBAAP;AACD,GArBD;;AAuBAhE,sEAEEc,eAFF,EAE4B;AAE1B,QAAMoD,yBAAyB,GAAG,KAAK5B,YAAL,CAChC,KAAKhB,EAAL,CAAQ,CAAR,CADgC,EAEhCR,eAFgC,CAAlC;AAIA,WAAOoD,yBAAP;AACD,GATD;;AAWAlE,6DAEEmE,YAFF,EAEyB;AAEvB,QAAMC,SAAS,GAAG,KAAKC,gBAAL,EAAlB;AACA,QAAMC,oBAAoB,GAAG,KAAKC,yBAAL,CAA+BH,SAA/B,CAA7B;AACA,WAAO,sBAASE,oBAAT,EAA+BH,YAA/B,CAAP;AACD,GAPD;;AASAnE;AACE,QAAMwE,yBAAyB,GAAG,KAAKC,gBAAL,EAAlC,CADF,CAEE;;AACA,QAAIC,SAAS,GAAG,KAAKpD,EAAL,CAAQ,CAAR,CAAhB;AACA,QAAIqD,CAAC,GAAG,CAAR;;AACA,WAAO,IAAP,EAAa;AACX,UAAMC,aAAa,GAAQF,SAAS,CAACG,SAArC;;AACA,UAAI,sBAASL,yBAAT,EAAoCI,aAApC,CAAJ,EAAwD;AACtD,eAAOA,aAAP;AACD;;AACDF,eAAS,GAAG,KAAKpD,EAAL,CAAQqD,CAAR,CAAZ;AACAA,OAAC;AACF;AACF,GAbD;;AAeA3E;AACE;AACA,QAAI,KAAK8E,UAAL,CAAgBC,MAAhB,KAA2B,CAA/B,EAAkC;AAChC,aAAOrF,sBAAP;AACD;;AACD,QAAMsF,iBAAiB,GAAG,KAAKC,4BAAL,EAA1B;AACA,QAAMC,WAAW,GAAG,KAAKC,kCAAL,EAApB;AACA,QAAMC,iBAAiB,GAAG,KAAKC,gCAAL,EAA1B;AAEA,WAAO;AACLpD,cAAQ,EAAE,KAAKqD,uBAAL,CAA6BN,iBAA7B,CADL;AAELO,sBAAgB,EAAEL,WAFb;AAGLM,YAAM,EAAE,KAAKF,uBAAL,CAA6BF,iBAA7B;AAHH,KAAP;AAKD,GAdD;;AAgBApF;AAAA;;AACE,QAAMyF,iBAAiB,GAAG,KAAKX,UAA/B;AACA,QAAMY,uBAAuB,GAAG,KAAKC,qBAArC;AAEA,WAAO,iBAAIF,iBAAJ,EAAuB,UAACxD,QAAD,EAAW2D,GAAX,EAAc;AAC1C,UAAIA,GAAG,KAAK,CAAZ,EAAe;AACb,eAAOlG,sBAAP;AACD;;AACD,aAAO;AACLuC,gBAAQ,EAAEP,KAAI,CAAC4D,uBAAL,CAA6BrD,QAA7B,CADL;AAELsD,wBAAgB,EAAEG,uBAAuB,CAACE,GAAD,CAFpC;AAGLJ,cAAM,EAAE9D,KAAI,CAAC4D,uBAAL,CAA6BG,iBAAiB,CAACG,GAAG,GAAG,CAAP,CAA9C;AAHH,OAAP;AAKD,KATM,CAAP;AAUD,GAdD;;AAgBA5F;AAAA;;AACE,QAAM6F,WAAW,GAAG,iBAAI,KAAKC,uBAAL,EAAJ,EAAoC,UAACC,OAAD,EAAQ;AAC9D,aAAOrE,KAAI,CAAC6C,yBAAL,CAA+BwB,OAA/B,CAAP;AACD,KAFmB,CAApB;AAGA,WAAY,qBAAQF,WAAR,CAAZ;AACD,GALD;;AAOA7F,8DAEEoE,SAFF,EAEuB;AAErB,QAAIA,SAAS,KAAK1E,sBAAlB,EAAkC;AAChC,aAAO,CAACsG,mBAAD,CAAP;AACD;;AAED,QAAMC,UAAU,GACd7B,SAAS,CAACnC,QAAV,GAAqBmC,SAAS,CAACmB,gBAA/B,GAAkDW,cAAlD,GAAuD9B,SAAS,CAACoB,MADnE;AAGA,WAAO,KAAKrF,aAAL,CAAmB8F,UAAnB,CAAP;AACD,GAZD,CA1RF,CAwSE;AACA;;;AACAjG,sDAEEmG,KAFF,EAGEC,YAHF,EAGwB;AAEtB,QAAI,CAAC,KAAK9D,YAAL,CAAkB6D,KAAlB,EAAyBH,mBAAzB,CAAL,EAAoC;AAClCI,kBAAY,CAACC,IAAb,CAAkBF,KAAlB;AACD;;AACD,WAAOC,YAAP;AACD,GATD;;AAWApG,6CAA8BO,OAA9B,EAAgD;AAC9C,QAAMY,cAAc,GAAG,EAAvB;AACA,QAAIwC,OAAO,GAAG,KAAKrC,EAAL,CAAQ,CAAR,CAAd;;AACA,WAAO,KAAKgB,YAAL,CAAkBqB,OAAlB,EAA2BpD,OAA3B,MAAwC,KAA/C,EAAsD;AACpDoD,aAAO,GAAG,KAAKlB,UAAL,EAAV;AACA,WAAKC,iBAAL,CAAuBiB,OAAvB,EAAgCxC,cAAhC;AACD,KAN6C,CAO9C;;;AACA,WAAO,uBAAUA,cAAV,CAAP;AACD,GATD;;AAWAnB,gEAEEsG,QAFF,EAGEC,IAHF,EAIEC,aAJF,EAKEC,YALF,EAMEC,cANF,EAOEC,cAPF,EAQE7D,QARF,EAQoB,CAElB;AACA;AACD,GAZD;;AAcA9C,0DAEEO,OAFF,EAGE4C,YAHF,EAGsB;AAEpB,QAAMyD,aAAa,GAAa,KAAKC,yBAAL,EAAhC;AACA,QAAMC,mBAAmB,GAAa,sBAAS,KAAKnB,qBAAd,CAAtC;AACA,QAAMvC,WAAW,GAAQ;AACvB2D,eAAS,EAAEH,aADY;AAEvBI,qBAAe,EAAEF,mBAFM;AAGvBG,aAAO,EAAE1G,OAHc;AAIvB2G,uBAAiB,EAAE/D;AAJI,KAAzB;AAOA,WAAOC,WAAP;AACD,GAfD;;AAgBApD;AAAA;;AACE,WAAO,iBAAI,KAAK8E,UAAT,EAAqB,UAACqC,aAAD,EAAc;AACxC,kBAAI,CAAC7B,uBAAL,CAA6B6B,aAA7B;AAA2C,KADtC,CAAP;AAGD,GAJD;;AAKF;AAAC,CAnWD;;AAAazH;;AAqWb,SAAgBY,2BAAhB,CAEEgG,QAFF,EAGEC,IAHF,EAIEC,aAJF,EAKEC,YALF,EAMEC,cANF,EAOEC,cAPF,EAQE7D,QARF,EAQoB;AAElB,MAAMsE,GAAG,GAAG,KAAKC,2BAAL,CAAiCZ,YAAjC,EAA+CC,cAA/C,CAAZ;AACA,MAAIY,iBAAiB,GAAG,KAAKpH,gBAAL,CAAsBkH,GAAtB,CAAxB;;AACA,MAAIE,iBAAiB,KAAKvE,SAA1B,EAAqC;AACnC,QAAMwE,YAAY,GAAG,KAAKrF,mBAAL,EAArB;AACA,QAAMsF,WAAW,GAAG,KAAKC,kBAAL,GAA0BF,YAA1B,CAApB;AACA,QAAMG,MAAM,GACV,IAAIf,cAAJ,CAAmBa,WAAnB,EAAgCd,cAAhC,CADF;AAEAY,qBAAiB,GAAGI,MAAM,CAACC,YAAP,EAApB;AACA,SAAKzH,gBAAL,CAAsBkH,GAAtB,IAA6BE,iBAA7B;AACD;;AAED,MAAI1E,uBAAuB,GAAG0E,iBAAiB,CAACnB,KAAhD;AACA,MAAItD,UAAU,GAAGyE,iBAAiB,CAACM,UAAnC;AACA,MAAMC,WAAW,GAAGP,iBAAiB,CAACO,WAAtC,CAfkB,CAiBlB;AACA;;AACA,MACE,KAAK/C,UAAL,CAAgBC,MAAhB,KAA2B,CAA3B,IACA8C,WADA,IAEAjF,uBAAuB,KAAKG,SAH9B,EAIE;AACAH,2BAAuB,GAAGoD,mBAA1B;AACAnD,cAAU,GAAG,CAAb;AACD;;AAED,MACE,KAAKiF,iCAAL,CACElF,uBADF,EAEEC,UAFF,EAGEC,QAHF,CADF,EAME;AACA;AACA;AACA;AACA,SAAKiF,uBAAL,CACEzB,QADF,EAEEC,IAFF,EAGEC,aAHF,EAIE5D,uBAJF;AAMD;AACF;;AArDDlD","names":["exports","InRuleRecoveryException","message","name","prototype","Error","Recoverable","config","firstAfterRepMap","resyncFollows","recoveryEnabled","parser_1","attemptInRepetitionRecovery","tokType","tokToInsert","NaN","isInsertedInRecovery","grammarRule","grammarRuleArgs","lookAheadFunc","expectedTokType","reSyncTokType","findReSyncTokenType","savedLexerState","exportLexerState","resyncedTokens","passedResyncPoint","nextTokenWithoutResync","LA","currToken","generateErrorMessage","previousToken","_this","msg","errorMessageProvider","buildMismatchTokenMessage","expected","actual","previous","ruleName","getCurrRuleFullName","error","exceptions_public_1","SAVE_ERROR","tokenMatcher","call","apply","SKIP_TOKEN","addToResyncTokens","importLexerState","expectTokAfterLastMatch","nextTokIdx","notStuck","undefined","isBackTracking","canPerformInRuleRecovery","getFollowsForInRuleRecovery","tokIdxInRule","grammarPath","getCurrentGrammarPath","follows","getNextPossibleTokenTypes","canRecoverWithSingleTokenInsertion","getTokenToInsert","canRecoverWithSingleTokenDeletion","nextTok","consumeToken","expectedToken","canTokenTypeBeInsertedInRecovery","mismatchedTok","isMisMatchedTokInFollows","possibleFollowsTokType","isNextTokenWhatIsExpected","tokenTypeIdx","followKey","getCurrFollowKey","currentRuleReSyncSet","getFollowSetFromFollowKey","allPossibleReSyncTokTypes","flattenFollowSet","nextToken","k","nextTokenType","tokenType","RULE_STACK","length","currRuleShortName","getLastExplicitRuleShortName","currRuleIdx","getLastExplicitRuleOccurrenceIndex","prevRuleShortName","getPreviousExplicitRuleShortName","shortRuleNameToFullName","idxInCallingRule","inRule","explicitRuleStack","explicitOccurrenceStack","RULE_OCCURRENCE_STACK","idx","followStack","buildFullFollowKeyStack","currKey","tokens_public_1","followName","constants_1","token","resyncTokens","push","prodFunc","args","lookaheadFunc","dslMethodIdx","prodOccurrence","nextToksWalker","pathRuleStack","getHumanReadableRuleStack","pathOccurrenceStack","ruleStack","occurrenceStack","lastTok","lastTokOccurrence","currShortName","key","getKeyForAutomaticLookahead","firstAfterRepInfo","currRuleName","ruleGrammar","getGAstProductions","walker","startWalking","occurrence","isEndOfRule","shouldInRepetitionRecoveryBeTried","tryInRepetitionRecovery"],"sources":["/Users/arbus/Documents/SpaceInBrowser/node_modules/chevrotain/src/parse/parser/traits/recoverable.ts"],"sourcesContent":["import { createTokenInstance, EOF } from \"../../../scan/tokens_public\"\nimport {\n  AbstractNextTerminalAfterProductionWalker,\n  IFirstAfterRepetition\n} from \"../../grammar/interpreter\"\nimport {\n  cloneArr,\n  contains,\n  dropRight,\n  find,\n  flatten,\n  has,\n  isEmpty,\n  map\n} from \"@chevrotain/utils\"\nimport {\n  IParserConfig,\n  IToken,\n  ITokenGrammarPath,\n  TokenType\n} from \"@chevrotain/types\"\nimport { MismatchedTokenException } from \"../../exceptions_public\"\nimport { IN } from \"../../constants\"\nimport { MixedInParser } from \"./parser_traits\"\nimport { DEFAULT_PARSER_CONFIG } from \"../parser\"\n\nexport const EOF_FOLLOW_KEY: any = {}\n\nexport interface IFollowKey {\n  ruleName: string\n  idxInCallingRule: number\n  inRule: string\n}\n\nexport const IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\"\n\nexport function InRuleRecoveryException(message: string) {\n  this.name = IN_RULE_RECOVERY_EXCEPTION\n  this.message = message\n}\n\nInRuleRecoveryException.prototype = Error.prototype\n\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\nexport class Recoverable {\n  recoveryEnabled: boolean\n  firstAfterRepMap: Record<string, IFirstAfterRepetition>\n  resyncFollows: Record<string, TokenType[]>\n\n  initRecoverable(config: IParserConfig) {\n    this.firstAfterRepMap = {}\n    this.resyncFollows = {}\n\n    this.recoveryEnabled = has(config, \"recoveryEnabled\")\n      ? config.recoveryEnabled\n      : DEFAULT_PARSER_CONFIG.recoveryEnabled\n\n    // performance optimization, NOOP will be inlined which\n    // effectively means that this optional feature does not exist\n    // when not used.\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery\n    }\n  }\n\n  public getTokenToInsert(tokType: TokenType): IToken {\n    const tokToInsert = createTokenInstance(\n      tokType,\n      \"\",\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN\n    )\n    tokToInsert.isInsertedInRecovery = true\n    return tokToInsert\n  }\n\n  public canTokenTypeBeInsertedInRecovery(tokType: TokenType) {\n    return true\n  }\n\n  tryInRepetitionRecovery(\n    this: MixedInParser,\n    grammarRule: Function,\n    grammarRuleArgs: any[],\n    lookAheadFunc: () => boolean,\n    expectedTokType: TokenType\n  ): void {\n    // TODO: can the resyncTokenType be cached?\n    const reSyncTokType = this.findReSyncTokenType()\n    const savedLexerState = this.exportLexerState()\n    const resyncedTokens = []\n    let passedResyncPoint = false\n\n    const nextTokenWithoutResync = this.LA(1)\n    let currToken = this.LA(1)\n\n    const generateErrorMessage = () => {\n      const previousToken = this.LA(0)\n      // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n      // the error that would have been thrown\n      const msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName()\n      })\n      const error = new MismatchedTokenException(\n        msg,\n        nextTokenWithoutResync,\n        this.LA(0)\n      )\n      // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n      error.resyncedTokens = dropRight(resyncedTokens)\n      this.SAVE_ERROR(error)\n    }\n\n    while (!passedResyncPoint) {\n      // re-synced to a point where we can safely exit the repetition/\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage()\n        return // must return here to avoid reverting the inputIdx\n      } else if (lookAheadFunc.call(this)) {\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n        generateErrorMessage()\n        // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n        grammarRule.apply(this, grammarRuleArgs)\n        return // must return here to avoid reverting the inputIdx\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true\n      } else {\n        currToken = this.SKIP_TOKEN()\n        this.addToResyncTokens(currToken, resyncedTokens)\n      }\n    }\n\n    // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n    // \"between rules\" resync recovery later in the flow.\n    this.importLexerState(savedLexerState)\n  }\n\n  shouldInRepetitionRecoveryBeTried(\n    this: MixedInParser,\n    expectTokAfterLastMatch: TokenType,\n    nextTokIdx: number,\n    notStuck: boolean | undefined\n  ): boolean {\n    // Edge case of arriving from a MANY repetition which is stuck\n    // Attempting recovery in this case could cause an infinite loop\n    if (notStuck === false) {\n      return false\n    }\n\n    // arguments to try and perform resync into the next iteration of the many are missing\n    if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n      return false\n    }\n\n    // no need to recover, next token is what we expect...\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false\n    }\n\n    // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n    // and prefer some backtracking path that includes recovered errors.\n    if (this.isBackTracking()) {\n      return false\n    }\n\n    // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n    //noinspection RedundantIfStatementJS\n    if (\n      this.canPerformInRuleRecovery(\n        expectTokAfterLastMatch,\n        this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx)\n      )\n    ) {\n      return false\n    }\n\n    return true\n  }\n\n  // Error Recovery functionality\n  getFollowsForInRuleRecovery(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number\n  ): TokenType[] {\n    const grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule)\n    const follows = this.getNextPossibleTokenTypes(grammarPath)\n    return follows\n  }\n\n  tryInRuleRecovery(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[]\n  ): IToken {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      const tokToInsert = this.getTokenToInsert(expectedTokType)\n      return tokToInsert\n    }\n\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      const nextTok = this.SKIP_TOKEN()\n      this.consumeToken()\n      return nextTok\n    }\n\n    throw new InRuleRecoveryException(\"sad sad panda\")\n  }\n\n  canPerformInRuleRecovery(\n    this: MixedInParser,\n    expectedToken: TokenType,\n    follows: TokenType[]\n  ): boolean {\n    return (\n      this.canRecoverWithSingleTokenInsertion(expectedToken, follows) ||\n      this.canRecoverWithSingleTokenDeletion(expectedToken)\n    )\n  }\n\n  canRecoverWithSingleTokenInsertion(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[]\n  ): boolean {\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false\n    }\n\n    // must know the possible following tokens to perform single token insertion\n    if (isEmpty(follows)) {\n      return false\n    }\n\n    const mismatchedTok = this.LA(1)\n    const isMisMatchedTokInFollows =\n      find(follows, (possibleFollowsTokType: TokenType) => {\n        return this.tokenMatcher(mismatchedTok, possibleFollowsTokType)\n      }) !== undefined\n\n    return isMisMatchedTokInFollows\n  }\n\n  canRecoverWithSingleTokenDeletion(\n    this: MixedInParser,\n    expectedTokType: TokenType\n  ): boolean {\n    const isNextTokenWhatIsExpected = this.tokenMatcher(\n      this.LA(2),\n      expectedTokType\n    )\n    return isNextTokenWhatIsExpected\n  }\n\n  isInCurrentRuleReSyncSet(\n    this: MixedInParser,\n    tokenTypeIdx: TokenType\n  ): boolean {\n    const followKey = this.getCurrFollowKey()\n    const currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey)\n    return contains(currentRuleReSyncSet, tokenTypeIdx)\n  }\n\n  findReSyncTokenType(this: MixedInParser): TokenType {\n    const allPossibleReSyncTokTypes = this.flattenFollowSet()\n    // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n    let nextToken = this.LA(1)\n    let k = 2\n    while (true) {\n      const nextTokenType: any = nextToken.tokenType\n      if (contains(allPossibleReSyncTokTypes, nextTokenType)) {\n        return nextTokenType\n      }\n      nextToken = this.LA(k)\n      k++\n    }\n  }\n\n  getCurrFollowKey(this: MixedInParser): IFollowKey {\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n    if (this.RULE_STACK.length === 1) {\n      return EOF_FOLLOW_KEY\n    }\n    const currRuleShortName = this.getLastExplicitRuleShortName()\n    const currRuleIdx = this.getLastExplicitRuleOccurrenceIndex()\n    const prevRuleShortName = this.getPreviousExplicitRuleShortName()\n\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName)\n    }\n  }\n\n  buildFullFollowKeyStack(this: MixedInParser): IFollowKey[] {\n    const explicitRuleStack = this.RULE_STACK\n    const explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK\n\n    return map(explicitRuleStack, (ruleName, idx) => {\n      if (idx === 0) {\n        return EOF_FOLLOW_KEY\n      }\n      return {\n        ruleName: this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: this.shortRuleNameToFullName(explicitRuleStack[idx - 1])\n      }\n    })\n  }\n\n  flattenFollowSet(this: MixedInParser): TokenType[] {\n    const followStack = map(this.buildFullFollowKeyStack(), (currKey) => {\n      return this.getFollowSetFromFollowKey(currKey)\n    })\n    return <any>flatten(followStack)\n  }\n\n  getFollowSetFromFollowKey(\n    this: MixedInParser,\n    followKey: IFollowKey\n  ): TokenType[] {\n    if (followKey === EOF_FOLLOW_KEY) {\n      return [EOF]\n    }\n\n    const followName =\n      followKey.ruleName + followKey.idxInCallingRule + IN + followKey.inRule\n\n    return this.resyncFollows[followName]\n  }\n\n  // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n  addToResyncTokens(\n    this: MixedInParser,\n    token: IToken,\n    resyncTokens: IToken[]\n  ): IToken[] {\n    if (!this.tokenMatcher(token, EOF)) {\n      resyncTokens.push(token)\n    }\n    return resyncTokens\n  }\n\n  reSyncTo(this: MixedInParser, tokType: TokenType): IToken[] {\n    const resyncedTokens = []\n    let nextTok = this.LA(1)\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN()\n      this.addToResyncTokens(nextTok, resyncedTokens)\n    }\n    // the last token is not part of the error.\n    return dropRight(resyncedTokens)\n  }\n\n  attemptInRepetitionRecovery(\n    this: MixedInParser,\n    prodFunc: Function,\n    args: any[],\n    lookaheadFunc: () => boolean,\n    dslMethodIdx: number,\n    prodOccurrence: number,\n    nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n    notStuck?: boolean\n  ): void {\n    // by default this is a NO-OP\n    // The actual implementation is with the function(not method) below\n  }\n\n  getCurrentGrammarPath(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number\n  ): ITokenGrammarPath {\n    const pathRuleStack: string[] = this.getHumanReadableRuleStack()\n    const pathOccurrenceStack: number[] = cloneArr(this.RULE_OCCURRENCE_STACK)\n    const grammarPath: any = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule\n    }\n\n    return grammarPath\n  }\n  getHumanReadableRuleStack(this: MixedInParser): string[] {\n    return map(this.RULE_STACK, (currShortName) =>\n      this.shortRuleNameToFullName(currShortName)\n    )\n  }\n}\n\nexport function attemptInRepetitionRecovery(\n  this: MixedInParser,\n  prodFunc: Function,\n  args: any[],\n  lookaheadFunc: () => boolean,\n  dslMethodIdx: number,\n  prodOccurrence: number,\n  nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n  notStuck?: boolean\n) {\n  const key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence)\n  let firstAfterRepInfo = this.firstAfterRepMap[key]\n  if (firstAfterRepInfo === undefined) {\n    const currRuleName = this.getCurrRuleFullName()\n    const ruleGrammar = this.getGAstProductions()[currRuleName]\n    const walker: AbstractNextTerminalAfterProductionWalker =\n      new nextToksWalker(ruleGrammar, prodOccurrence)\n    firstAfterRepInfo = walker.startWalking()\n    this.firstAfterRepMap[key] = firstAfterRepInfo\n  }\n\n  let expectTokAfterLastMatch = firstAfterRepInfo.token\n  let nextTokIdx = firstAfterRepInfo.occurrence\n  const isEndOfRule = firstAfterRepInfo.isEndOfRule\n\n  // special edge case of a TOP most repetition after which the input should END.\n  // this will force an attempt for inRule recovery in that scenario.\n  if (\n    this.RULE_STACK.length === 1 &&\n    isEndOfRule &&\n    expectTokAfterLastMatch === undefined\n  ) {\n    expectTokAfterLastMatch = EOF\n    nextTokIdx = 1\n  }\n\n  if (\n    this.shouldInRepetitionRecoveryBeTried(\n      expectTokAfterLastMatch,\n      nextTokIdx,\n      notStuck\n    )\n  ) {\n    // TODO: performance optimization: instead of passing the original args here, we modify\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n    // to avoid searching the cache for it once more.\n    this.tryInRepetitionRecovery(\n      prodFunc,\n      args,\n      lookaheadFunc,\n      expectTokAfterLastMatch\n    )\n  }\n}\n"]},"metadata":{},"sourceType":"script"}